{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import QAGenerationChain\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.evaluation import EmbeddingDistance\n",
    "from langchain.evaluation import load_evaluator, EvaluatorType\n",
    "from langchain.evaluation.schema import StringEvaluator\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.schema import BaseRetriever\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from src.prompt_templates import MULTI_QA_GPT35_PROMPT_TEMPLATE, GRADE_DOCS_PROMPT_TEMPLATE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"../linux-kernel\"\n",
    "\n",
    "docs = []\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    for file in filenames:\n",
    "        if file.endswith(\".c\") and \"/.venv/\" not in dirpath:\n",
    "            try:\n",
    "                loader = TextLoader(os.path.join(dirpath, file), encoding=\"utf-8\")\n",
    "                docs.extend(loader.load())\n",
    "            except Exception as e:\n",
    "                pass\n",
    "print(f\"{len(docs)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1227\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    Language,\n",
    ")\n",
    "\n",
    "RecursiveCharacterTextSplitter.get_separators_for_language(Language.CPP)\n",
    "\n",
    "cpp_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.CPP, chunk_size=250, chunk_overlap=50\n",
    ")\n",
    "chunks = cpp_splitter.split_documents(docs)\n",
    "print(f\"{len(chunks)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    model_kwargs={'device': 'cuda'},\n",
    "    encode_kwargs={'normalize_embeddings': False}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watson/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/embeddings/openai.py:214: UserWarning: WARNING! deployment_name is not default parameter.\n",
      "                    deployment_name was transferred to model_kwargs.\n",
      "                    Please confirm that deployment_name is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "openai_azure_embeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=\"02e3dbabaf334ccb959cbeadbd3f99c3\",\n",
    "    openai_api_base=\"https://llm-x-gpt.openai.azure.com/\",\n",
    "    deployment_name='LLM-X-Embedding',\n",
    "    openai_api_version=\"2023-03-15-preview\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "hf_embeddings_vector_db = FAISS.from_documents(chunks, hf_embeddings)\n",
    "hf_embeddings_vector_db.save_local(\"linux-kernel_embeddings\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "doc 0:\n",
      " *\n",
      " * __get_user_pages walks a process's page tables and takes a reference to\n",
      " * each struct page that each user address corresponds to at a given\n",
      " * instant. That is, it takes the page that would be accessed if a user\n",
      "\n",
      "\n",
      "\n",
      "doc 1:\n",
      " * trying again.\n",
      " *\n",
      " * Typically this is meant to be used by the futex code.\n",
      " *\n",
      " * The main difference with get_user_pages() is that this function will\n",
      " * unconditionally call handle_mm_fault() which will in turn perform all the\n",
      "\n",
      "\n",
      "\n",
      "doc 2:\n",
      " *\n",
      " * get_user_pages_remote walks a process's page tables and takes a reference\n",
      " * to each struct page that each user address corresponds to at a given\n",
      " * instant. That is, it takes the page that would be accessed if a user\n",
      "\n",
      "\n",
      "\n",
      "doc 3:\n",
      " *\n",
      " * get_user_pages_remote is typically used for fewer-copy IO operations,\n",
      " * to get a handle on the memory by some means other than accesses\n",
      " * via the user virtual addresses. The pages may be submitted for\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the purpose of the get_user_page in the linux kernel?\"\n",
    "retrieved_chunks = hf_embeddings_vector_db.similarity_search(question)\n",
    "for i, retrieved_chunk in enumerate(retrieved_chunks):\n",
    "    print(f\"\\n\\n\\ndoc {i}:\\n {retrieved_chunk.page_content}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "gpt35_azure_llm = AzureChatOpenAI(\n",
    "    temperature=0,\n",
    "    openai_api_key=\"02e3dbabaf334ccb959cbeadbd3f99c3\",\n",
    "    openai_api_base=\"https://llm-x-gpt.openai.azure.com/\",\n",
    "    deployment_name='LLM-X-GPT35-TURBO',\n",
    "    openai_api_version=\"2023-03-15-preview\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "gpt4_azure_llm = AzureChatOpenAI(\n",
    "    temperature=0,\n",
    "    openai_api_key=\"a8d69f68a36b40789df2cc3fdbaacda9\",\n",
    "    openai_api_base=\"https://llmx-gpt-canada-east.openai.azure.com/\",\n",
    "    deployment_name='LLM-X-GPT-4',\n",
    "    openai_api_version=\"2023-03-15-preview\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "{'query': 'What is the purpose of the get_user_page in the linux kernel?',\n 'result': \"The purpose of the get_user_pages() function in the Linux kernel is to pin user pages in memory. It allows the kernel to obtain references to the physical pages that correspond to a given user virtual address. This is useful when the kernel needs to access or manipulate user memory, such as when submitting pages for DMA to devices or accessing them via the kernel linear mapping. The function ensures that the pages won't be freed completely and guarantees that the page contains data that was valid at some point in time. The caller is responsible for releasing the returned pages using put_page().\"}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=gpt35_azure_llm,\n",
    "    retriever=hf_embeddings_vector_db.as_retriever()\n",
    ")\n",
    "\n",
    "qa_rag_chain({\"query\": question})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "multi_qa_prompt = PromptTemplate.from_template(template=MULTI_QA_GPT35_PROMPT_TEMPLATE,\n",
    "                                               partial_variables={\"k\": 2})\n",
    "qa_generation_chain = QAGenerationChain.from_llm(llm=gpt35_azure_llm,\n",
    "                                                 prompt=multi_qa_prompt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. What is the function of the get_user_page in the linux kernel?', '2. How does the get_user_page function serve its purpose in the linux kernel?', '3. Can you explain the role and significance of the get_user_page in the linux kernel?']\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig()\n",
    "logging.getLogger('langchain.retrievers.multi_query').setLevel(logging.INFO)\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=hf_embeddings_vector_db.as_retriever(),\n",
    "    llm=gpt35_azure_llm\n",
    ")\n",
    "\n",
    "unique_docs = retriever_from_llm.get_relevant_documents(query=question)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def create_qna_GT_df(docs: List[Document], num_of_qna_for_doc: int) -> pd.DataFrame:\n",
    "    multi_qa_prompt = PromptTemplate.from_template(template=MULTI_QA_GPT35_PROMPT_TEMPLATE,\n",
    "                                                   partial_variables={\"k\": num_of_qna_for_doc})\n",
    "    qa_generation_chain = QAGenerationChain.from_llm(llm=gpt35_azure_llm,\n",
    "                                                     prompt=multi_qa_prompt)\n",
    "\n",
    "    qna_GT = []\n",
    "    for doc in docs:\n",
    "        doc_qna = qa_generation_chain.run(doc.page_content)\n",
    "        qna_GT += doc_qna\n",
    "\n",
    "    qna_GT_df = pd.DataFrame(qna_GT)\n",
    "    return qna_GT_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def get_qna_with_chain_answers_df(qa_rag_chain: RetrievalQA, qna_GT_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    qna_with_chain_answers = qna_GT_df.copy()\n",
    "    qna_with_chain_answers[\"chain_answer\"] = qna_with_chain_answers.apply(\n",
    "        lambda qna: qa_rag_chain({\"query\": qna[\"question\"]})[\"result\"], axis=1)\n",
    "\n",
    "    return qna_with_chain_answers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def get_evaluator_score(evaluator: StringEvaluator, qna_with_chain_answer: pd.Series) -> float:\n",
    "    grade = evaluator.evaluate_strings(\n",
    "        prediction=qna_with_chain_answer[\"chain_answer\"],\n",
    "        reference=qna_with_chain_answer[\"answer\"],\n",
    "        input=qna_with_chain_answer[\"question\"])\n",
    "\n",
    "    return grade[\"score\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def get_retrieval_score(retriever, qna_with_chain_answer: pd.Series):\n",
    "    GRADE_DOCS_PROMPT = PromptTemplate(input_variables=['result', 'answer', 'query'],\n",
    "                                       template=GRADE_DOCS_PROMPT_TEMPLATE)\n",
    "    retrieval_eval_chain = load_evaluator(\n",
    "        evaluator=EvaluatorType.QA,\n",
    "        llm=gpt35_azure_llm,\n",
    "        prompt=GRADE_DOCS_PROMPT\n",
    "    )\n",
    "\n",
    "    retrieved_docs = retriever.get_relevant_documents(query=qna_with_chain_answer[\"question\"],\n",
    "                                                      search_type=\"similarity_score_threshold\",\n",
    "                                                      search_kwargs={\"k\": 2})\n",
    "\n",
    "    grade = retrieval_eval_chain.evaluate_strings(\n",
    "        prediction=retrieved_docs,\n",
    "        reference=qna_with_chain_answer[\"answer\"],\n",
    "        input=qna_with_chain_answer[\"question\"])\n",
    "\n",
    "    return grade[\"score\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def get_grades_for_chain_qna(qna_with_chain_answers_df: pd.DataFrame,\n",
    "                             retriever: BaseRetriever = None) -> pd.DataFrame:\n",
    "    grades_for_chain_qna = qna_with_chain_answers_df.copy()\n",
    "\n",
    "    labeled_criteria_evaluator = load_evaluator(evaluator=EvaluatorType.LABELED_CRITERIA,\n",
    "                                                criteria=\"correctness\",\n",
    "                                                llm=gpt35_azure_llm)\n",
    "\n",
    "    embedding_distance_evaluator = load_evaluator(evaluator=EvaluatorType.EMBEDDING_DISTANCE,\n",
    "                                                  distance_metric=EmbeddingDistance.COSINE,\n",
    "                                                  embeddings=hf_embeddings,\n",
    "                                                  llm=gpt35_azure_llm)\n",
    "\n",
    "    qa_llm_jugde_evaluator = load_evaluator(evaluator=EvaluatorType.QA,\n",
    "                                            llm=gpt35_azure_llm)\n",
    "\n",
    "    grades_for_chain_qna[\"labeled_criteria_grades\"] = qna_with_chain_answers_df.apply(\n",
    "        lambda qna_with_chain_answer: get_evaluator_score(\n",
    "            evaluator=labeled_criteria_evaluator,\n",
    "            qna_with_chain_answer=qna_with_chain_answer), axis=1)\n",
    "\n",
    "    grades_for_chain_qna[\"embedding_distance_grades\"] = qna_with_chain_answers_df.apply(\n",
    "        lambda qna_with_chain_answer: get_evaluator_score(\n",
    "            evaluator=embedding_distance_evaluator,\n",
    "            qna_with_chain_answer=qna_with_chain_answer), axis=1)\n",
    "\n",
    "    grades_for_chain_qna[\"qa_llm_jugde_grades\"] = qna_with_chain_answers_df.apply(\n",
    "        lambda qna_with_chain_answer: get_evaluator_score(\n",
    "            evaluator=qa_llm_jugde_evaluator,\n",
    "            qna_with_chain_answer=qna_with_chain_answer), axis=1)\n",
    "\n",
    "    if retriever:\n",
    "        grades_for_chain_qna[\"retrieval_score\"] = qna_with_chain_answers_df.apply(\n",
    "            lambda qna_with_chain_answer: get_retrieval_score(\n",
    "                retriever=retriever,\n",
    "                qna_with_chain_answer=qna_with_chain_answer), axis=1)\n",
    "\n",
    "    return grades_for_chain_qna"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def run_evaluation(qa_rag_chain: RetrievalQA, qna_GT_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    qna_with_chain_answers_df = get_qna_with_chain_answers_df(qa_rag_chain, qna_GT_df)\n",
    "    grades_for_chain_qna = \\\n",
    "        get_grades_for_chain_qna(qna_with_chain_answers_df=qna_with_chain_answers_df,\n",
    "                                 retriever=qa_rag_chain.retriever)\n",
    "    return grades_for_chain_qna"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "qna_GT_df = create_qna_GT_df(docs=docs, num_of_qna_for_doc=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "langchain_qa_generation_chain = QAGenerationChain.from_llm(llm=gpt4_azure_llm)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "from src.prompt_templates import MULTI_QA_GPT4_PROMPT_TEMPLATE\n",
    "\n",
    "multi_qa_prompt = PromptTemplate.from_template(template=MULTI_QA_GPT4_PROMPT_TEMPLATE,\n",
    "                                                   partial_variables={\"k\": 3})\n",
    "qa_generation_chain = QAGenerationChain.from_llm(llm=gpt4_azure_llm,\n",
    "                                                prompt=multi_qa_prompt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "37203"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = docs[0]\n",
    "len(doc.page_content)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mJSONDecodeError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[83], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m doc_qna \u001B[38;5;241m=\u001B[39m \u001B[43mlangchain_qa_generation_chain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdoc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpage_content\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m500\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/chains/base.py:451\u001B[0m, in \u001B[0;36mChain.run\u001B[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001B[0m\n\u001B[1;32m    449\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    450\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`run` supports only one positional argument.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 451\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadata\u001B[49m\u001B[43m)\u001B[49m[\n\u001B[1;32m    452\u001B[0m         _output_key\n\u001B[1;32m    453\u001B[0m     ]\n\u001B[1;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args:\n\u001B[1;32m    456\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m(kwargs, callbacks\u001B[38;5;241m=\u001B[39mcallbacks, tags\u001B[38;5;241m=\u001B[39mtags, metadata\u001B[38;5;241m=\u001B[39mmetadata)[\n\u001B[1;32m    457\u001B[0m         _output_key\n\u001B[1;32m    458\u001B[0m     ]\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/chains/base.py:258\u001B[0m, in \u001B[0;36mChain.__call__\u001B[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001B[0m\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    257\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n\u001B[0;32m--> 258\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    259\u001B[0m run_manager\u001B[38;5;241m.\u001B[39mon_chain_end(outputs)\n\u001B[1;32m    260\u001B[0m final_outputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(\n\u001B[1;32m    261\u001B[0m     inputs, outputs, return_only_outputs\n\u001B[1;32m    262\u001B[0m )\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/chains/base.py:252\u001B[0m, in \u001B[0;36mChain.__call__\u001B[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001B[0m\n\u001B[1;32m    246\u001B[0m run_manager \u001B[38;5;241m=\u001B[39m callback_manager\u001B[38;5;241m.\u001B[39mon_chain_start(\n\u001B[1;32m    247\u001B[0m     dumpd(\u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    248\u001B[0m     inputs,\n\u001B[1;32m    249\u001B[0m )\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 252\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    253\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[1;32m    254\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(inputs)\n\u001B[1;32m    255\u001B[0m     )\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    257\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/chains/qa_generation/base.py:76\u001B[0m, in \u001B[0;36mQAGenerationChain._call\u001B[0;34m(self, inputs, run_manager)\u001B[0m\n\u001B[1;32m     72\u001B[0m docs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtext_splitter\u001B[38;5;241m.\u001B[39mcreate_documents([inputs[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_key]])\n\u001B[1;32m     73\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm_chain\u001B[38;5;241m.\u001B[39mgenerate(\n\u001B[1;32m     74\u001B[0m     [{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m: d\u001B[38;5;241m.\u001B[39mpage_content} \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m docs], run_manager\u001B[38;5;241m=\u001B[39mrun_manager\n\u001B[1;32m     75\u001B[0m )\n\u001B[0;32m---> 76\u001B[0m qa \u001B[38;5;241m=\u001B[39m [json\u001B[38;5;241m.\u001B[39mloads(res[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mtext) \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m results\u001B[38;5;241m.\u001B[39mgenerations]\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_key: qa}\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/chains/qa_generation/base.py:76\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     72\u001B[0m docs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtext_splitter\u001B[38;5;241m.\u001B[39mcreate_documents([inputs[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_key]])\n\u001B[1;32m     73\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mllm_chain\u001B[38;5;241m.\u001B[39mgenerate(\n\u001B[1;32m     74\u001B[0m     [{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m: d\u001B[38;5;241m.\u001B[39mpage_content} \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m docs], run_manager\u001B[38;5;241m=\u001B[39mrun_manager\n\u001B[1;32m     75\u001B[0m )\n\u001B[0;32m---> 76\u001B[0m qa \u001B[38;5;241m=\u001B[39m [\u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mres\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m res \u001B[38;5;129;01min\u001B[39;00m results\u001B[38;5;241m.\u001B[39mgenerations]\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_key: qa}\n",
      "File \u001B[0;32m/opt/miniconda/lib/python3.9/json/__init__.py:346\u001B[0m, in \u001B[0;36mloads\u001B[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[1;32m    341\u001B[0m     s \u001B[38;5;241m=\u001B[39m s\u001B[38;5;241m.\u001B[39mdecode(detect_encoding(s), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msurrogatepass\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    344\u001B[0m         parse_int \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m parse_float \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    345\u001B[0m         parse_constant \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_pairs_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kw):\n\u001B[0;32m--> 346\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_decoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    348\u001B[0m     \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m JSONDecoder\n",
      "File \u001B[0;32m/opt/miniconda/lib/python3.9/json/decoder.py:337\u001B[0m, in \u001B[0;36mJSONDecoder.decode\u001B[0;34m(self, s, _w)\u001B[0m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode\u001B[39m(\u001B[38;5;28mself\u001B[39m, s, _w\u001B[38;5;241m=\u001B[39mWHITESPACE\u001B[38;5;241m.\u001B[39mmatch):\n\u001B[1;32m    333\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001B[39;00m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03m    containing a JSON document).\u001B[39;00m\n\u001B[1;32m    335\u001B[0m \n\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 337\u001B[0m     obj, end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraw_decode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_w\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    338\u001B[0m     end \u001B[38;5;241m=\u001B[39m _w(s, end)\u001B[38;5;241m.\u001B[39mend()\n\u001B[1;32m    339\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m end \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(s):\n",
      "File \u001B[0;32m/opt/miniconda/lib/python3.9/json/decoder.py:355\u001B[0m, in \u001B[0;36mJSONDecoder.raw_decode\u001B[0;34m(self, s, idx)\u001B[0m\n\u001B[1;32m    353\u001B[0m     obj, end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscan_once(s, idx)\n\u001B[1;32m    354\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m--> 355\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m JSONDecodeError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpecting value\u001B[39m\u001B[38;5;124m\"\u001B[39m, s, err\u001B[38;5;241m.\u001B[39mvalue) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    356\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj, end\n",
      "\u001B[0;31mJSONDecodeError\u001B[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "doc_qna = langchain_qa_generation_chain.run(doc.page_content[:500])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "doc_qna = qa_generation_chain.run(doc.page_content[:15000])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "qnas_in_doc = []\n",
    "for qna in doc_qna:\n",
    "    qnas_in_doc += qna"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'question': 'What does the module implemented in the given code do?',\n  'answer': 'The module implements the Address Resolution Protocol ARP (RFC 826), which is used to convert IP addresses into a low-level hardware address like an Ethernet address.'},\n {'question': 'What are some of the fixes and improvements made to the code according to the comments?',\n  'answer': 'Some of the fixes and improvements include removing Ethernet assumptions, fixing errors in the ARP logic, adding AX25 support, adding ARP netmask code, major changes to caching and behaviour, adding Frame Relay ARP support, and converting /proc/net/arp to seq_file among others.'},\n {'question': 'What is the purpose of the \\'#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\\' line in the code?',\n  'answer': 'This line is defining a macro for formatting print statements. It prepends the module name (KBUILD_MODNAME) and a colon to the format string for the print statement.'},\n {'question': 'What is the purpose of the arp_hash function in the provided code?',\n  'answer': 'The arp_hash function is used to compute a hash value for the given key and device. This is typically used in the context of a hash table, where the hash value is used to quickly locate the entry corresponding to the given key.'},\n {'question': 'What does the arp_constructor function do in the provided code?',\n  'answer': 'The arp_constructor function is used to initialize a neighbour structure. It sets the type of the neighbour based on the IP address, clones the neighbour parameters from the in_device structure, and sets the output function based on whether the device has header operations.'},\n {'question': 'What is the purpose of the arp_key_eq function in the provided code?',\n  'answer': 'The arp_key_eq function is used to compare the key of a neighbour structure with a given key. It returns true if the keys are equal and false otherwise.'},\n {'question': 'What happens if the device does not have header operations in the given code?',\n  'answer': 'If the device does not have header operations, the nud_state of the neighbor is set to NUD_NOARP, the ops of the neighbor is set to arp_direct_ops, and the output of the neighbor is set to neigh_direct_output.'},\n {'question': 'What is the purpose of the arp_send function in the given code?',\n  'answer': 'The arp_send function is used to create and send an ARP packet. It takes parameters such as type, ptype, destination IP, device, source IP, destination hardware address, source hardware address, and target hardware address.'},\n {'question': 'What does the arp_solicit function do in the given code?',\n  'answer': 'The arp_solicit function is used to send an ARP request. It takes a neighbor and a sk_buff as parameters. It gets the source address, destination hardware address, and the device from the neighbor. It then checks the ARP announce mode and selects an address accordingly. It also checks the number of probes and takes actions based on that.'},\n {'question': 'What does the function arp_ignore do?',\n  'answer': 'The arp_ignore function determines whether to ignore an ARP request based on the configuration of the incoming interface. It returns 0 to reply, 1 to ignore, or checks if the target IP is configured on the incoming interface and is in the same subnet as the source IP.'},\n {'question': 'What is the purpose of the arp_accept function?',\n  'answer': 'The arp_accept function determines whether to create new entries from gratuitous ARP (GARP) based on the configuration of the incoming interface. It returns 0 to not create new entries, 1 to create new entries, or checks if the source IP is in the same subnet as an address configured on the interface that received the GARP message.'},\n {'question': 'What does the arp_filter function do?',\n  'answer': 'The arp_filter function checks if the destination device of the route is the same as the incoming device. If not, it increments the LINUX_MIB_ARPFILTER statistic and sets a flag. The function returns 1 if the route output is an error or the flag is set, otherwise it returns 0.'},\n {'question': \"What does the code do if 'sip' is equal to 'tip'?\",\n  'answer': \"If 'sip' is equal to 'tip', the code returns 0.\"},\n {'question': \"What does the function return if 'IN_DEV_PROXY_ARP_PVLAN(in_dev)' is true?\",\n  'answer': \"If 'IN_DEV_PROXY_ARP_PVLAN(in_dev)' is true, the function returns 1.\"},\n {'question': \"What does the comment 'Create an arp packet. If dest_hw is not set, we create a broadcast' imply?\",\n  'answer': \"The comment implies that the code following it is responsible for creating an ARP packet. If the 'dest_hw' is not set, a broadcast is created instead.\"}]"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qnas_in_doc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'question': 'What does the function arp_ignore do?',\n  'answer': 'The arp_ignore function determines whether to ignore an ARP request based on the configuration of the incoming interface. It returns 0 to reply, 1 to ignore, or checks if the target IP is configured on the incoming interface and is in the same subnet as the source IP.'},\n {'question': 'What is the purpose of the arp_accept function?',\n  'answer': 'The arp_accept function determines whether to create new entries from gratuitous ARP (GARP) based on the configuration of the incoming interface. It returns 0 to not create new entries, 1 to create new entries, or checks if the source IP is in the same subnet as an address configured on the interface that received the GARP message.'},\n {'question': 'What does the arp_filter function do?',\n  'answer': 'The arp_filter function checks if the destination device of the route is the same as the incoming device. If not, it increments the LINUX_MIB_ARPFILTER statistic and sets a flag. The function returns 1 if the route output is an error or the flag is set, otherwise it returns 0.'}]"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_qna[3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "qna_GT_df.to_csv(\"6qna_linux.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watson/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/evaluation/schema.py:104: UserWarning: Ignoring input in EmbeddingDistanceEvalChain, as it is not expected.\n",
      "  warn(self._skip_input_warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                            question  \\\n0  What is the purpose of the 'for' loop in the g...   \n1  What does the variable 'fact' represent in the...   \n2             What is the purpose of the given code?   \n3    What is the return type of the 'fact' function?   \n4           What is the purpose of the code snippet?   \n5  What is the value of 'fact' after the code sni...   \n\n                                              answer  \\\n0  The 'for' loop is used to calculate the factor...   \n1  The variable 'fact' stores the factorial of th...   \n2  The purpose of the given code is to calculate ...   \n3   The return type of the 'fact' function is 'int'.   \n4  To calculate and display the factorial of a nu...   \n5    The factorial of the number entered by the user   \n\n                                        chain_answer  labeled_criteria_grades  \\\n0  The purpose of the 'for' loop in the given cod...                      NaN   \n1  In the given code, the variable 'fact' represe...                      1.0   \n2  The purpose of the given code is to input the ...                      NaN   \n3   The return type of the 'fact' function is 'int'.                      1.0   \n4  The purpose of the code snippet is to prompt t...                      NaN   \n5  The value of 'fact' cannot be determined witho...                      1.0   \n\n   embedding_distance_grades  qa_llm_jugde_grades  retrieval_score  \n0               3.103038e-01                    1              NaN  \n1               1.048536e-01                    1              1.0  \n2               6.754299e-01                    0              1.0  \n3              -2.220446e-16                    1              1.0  \n4               7.435595e-01                    0              NaN  \n5               5.335894e-01                    1              1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n      <th>chain_answer</th>\n      <th>labeled_criteria_grades</th>\n      <th>embedding_distance_grades</th>\n      <th>qa_llm_jugde_grades</th>\n      <th>retrieval_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is the purpose of the 'for' loop in the g...</td>\n      <td>The 'for' loop is used to calculate the factor...</td>\n      <td>The purpose of the 'for' loop in the given cod...</td>\n      <td>NaN</td>\n      <td>3.103038e-01</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What does the variable 'fact' represent in the...</td>\n      <td>The variable 'fact' stores the factorial of th...</td>\n      <td>In the given code, the variable 'fact' represe...</td>\n      <td>1.0</td>\n      <td>1.048536e-01</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What is the purpose of the given code?</td>\n      <td>The purpose of the given code is to calculate ...</td>\n      <td>The purpose of the given code is to input the ...</td>\n      <td>NaN</td>\n      <td>6.754299e-01</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What is the return type of the 'fact' function?</td>\n      <td>The return type of the 'fact' function is 'int'.</td>\n      <td>The return type of the 'fact' function is 'int'.</td>\n      <td>1.0</td>\n      <td>-2.220446e-16</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What is the purpose of the code snippet?</td>\n      <td>To calculate and display the factorial of a nu...</td>\n      <td>The purpose of the code snippet is to prompt t...</td>\n      <td>NaN</td>\n      <td>7.435595e-01</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>What is the value of 'fact' after the code sni...</td>\n      <td>The factorial of the number entered by the user</td>\n      <td>The value of 'fact' cannot be determined witho...</td>\n      <td>1.0</td>\n      <td>5.335894e-01</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_evaluation(qa_rag_chain=qa_rag_chain, qna_GT_df=qna_GT_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "embedding_distance_evaluator = load_evaluator(evaluator=EvaluatorType.EMBEDDING_DISTANCE,\n",
    "                                              distance_metric=EmbeddingDistance.COSINE,\n",
    "                                              embeddings=hf_embeddings,\n",
    "                                              llm=gpt35_azure_llm)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "{'score': 0.2272324479048582}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_distance_evaluator.evaluate_strings(\n",
    "    prediction=\"my dog like to eat dogs food\",\n",
    "    reference=\"my dog like to eat burgers\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "-2.220446e-16"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-2.220446e-16"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "langchain.evaluation.embedding_distance.base.EmbeddingDistanceEvalChain"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.evaluation import EmbeddingDistanceEvalChain\n",
    "\n",
    "type(embedding_distance_evaluator)\n",
    "EmbeddingDistanceEvalChain"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
