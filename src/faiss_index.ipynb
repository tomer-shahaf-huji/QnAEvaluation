{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from json import JSONDecodeError\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import QAGenerationChain, RetrievalQA\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.evaluation import EmbeddingDistance\n",
    "from langchain.evaluation import load_evaluator, EvaluatorType\n",
    "from langchain.evaluation.schema import StringEvaluator\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.schema import BaseRetriever\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
    "from langchain.vectorstores import FAISS\n",
    "from tqdm import tqdm\n",
    "from src.prompt_templates import MULTI_QA_GPT4_PROMPT_TEMPLATE, GRADE_DOCS_PROMPT_TEMPLATE\n",
    "from src.language_model_handlers.fastchat_llm import FastChatLLM\n",
    "\n",
    "INDEX_OF_FIRST_QNA_IN_RESPONSE = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"../linux-kernel\"\n",
    "\n",
    "docs = []\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    for file in filenames:\n",
    "        if file.endswith(\".c\") and \"/.venv/\" not in dirpath:\n",
    "            try:\n",
    "                loader = TextLoader(os.path.join(dirpath, file), encoding=\"utf-8\")\n",
    "                docs.extend(loader.load())\n",
    "            except Exception as e:\n",
    "                pass\n",
    "print(f\"{len(docs)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4290\n"
     ]
    }
   ],
   "source": [
    "RecursiveCharacterTextSplitter.get_separators_for_language(Language.CPP)\n",
    "\n",
    "chunks_cpp_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.CPP, chunk_size=250, chunk_overlap=50\n",
    ")\n",
    "chunks = chunks_cpp_splitter.split_documents(docs)\n",
    "print(f\"{len(chunks)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258\n"
     ]
    }
   ],
   "source": [
    "documents_cpp_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.CPP, chunk_size=4000, chunk_overlap=150\n",
    ")\n",
    "splitted_docs = documents_cpp_splitter.split_documents(docs)\n",
    "print(f\"{len(splitted_docs)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    model_kwargs={'device': 'cuda'},\n",
    "    encode_kwargs={'normalize_embeddings': False}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "openai_azure_embeddings = OpenAIEmbeddings(\n",
    "    openai_api_type=\"azure\",\n",
    "    openai_api_key=\"02e3dbabaf334ccb959cbeadbd3f99c3\",\n",
    "    openai_api_base=\"https://llm-x-gpt.openai.azure.com/\",\n",
    "    chunk_size=1\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "hf_embeddings_vector_db = FAISS.from_documents(chunks, hf_embeddings)\n",
    "hf_embeddings_vector_db.save_local(\"linux_kernel_hf_embeddings\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Requests to the Embeddings_Create Operation under Azure OpenAI API version 2022-12-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m openai_embeddings_vector_db \u001B[38;5;241m=\u001B[39m \u001B[43mFAISS\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mopenai_azure_embeddings\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m openai_embeddings_vector_db\u001B[38;5;241m.\u001B[39msave_local(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlinux_kernel_openai_embeddings\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/vectorstores/base.py:420\u001B[0m, in \u001B[0;36mVectorStore.from_documents\u001B[0;34m(cls, documents, embedding, **kwargs)\u001B[0m\n\u001B[1;32m    418\u001B[0m texts \u001B[38;5;241m=\u001B[39m [d\u001B[38;5;241m.\u001B[39mpage_content \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m documents]\n\u001B[1;32m    419\u001B[0m metadatas \u001B[38;5;241m=\u001B[39m [d\u001B[38;5;241m.\u001B[39mmetadata \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m documents]\n\u001B[0;32m--> 420\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_texts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/vectorstores/faiss.py:607\u001B[0m, in \u001B[0;36mFAISS.from_texts\u001B[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001B[0m\n\u001B[1;32m    581\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m    582\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfrom_texts\u001B[39m(\n\u001B[1;32m    583\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    588\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    589\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m FAISS:\n\u001B[1;32m    590\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001B[39;00m\n\u001B[1;32m    591\u001B[0m \n\u001B[1;32m    592\u001B[0m \u001B[38;5;124;03m    This is a user friendly interface that:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    605\u001B[0m \u001B[38;5;124;03m            faiss = FAISS.from_texts(texts, embeddings)\u001B[39;00m\n\u001B[1;32m    606\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 607\u001B[0m     embeddings \u001B[38;5;241m=\u001B[39m \u001B[43membedding\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    608\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m__from(\n\u001B[1;32m    609\u001B[0m         texts,\n\u001B[1;32m    610\u001B[0m         embeddings,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    614\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m    615\u001B[0m     )\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/embeddings/openai.py:478\u001B[0m, in \u001B[0;36mOpenAIEmbeddings.embed_documents\u001B[0;34m(self, texts, chunk_size)\u001B[0m\n\u001B[1;32m    466\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Call out to OpenAI's embedding endpoint for embedding search docs.\u001B[39;00m\n\u001B[1;32m    467\u001B[0m \n\u001B[1;32m    468\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    474\u001B[0m \u001B[38;5;124;03m    List of embeddings, one for each text.\u001B[39;00m\n\u001B[1;32m    475\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    476\u001B[0m \u001B[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001B[39;00m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001B[39;00m\n\u001B[0;32m--> 478\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_len_safe_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeployment\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/embeddings/openai.py:364\u001B[0m, in \u001B[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001B[0;34m(self, texts, engine, chunk_size)\u001B[0m\n\u001B[1;32m    361\u001B[0m     _iter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(tokens), _chunk_size)\n\u001B[1;32m    363\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m _iter:\n\u001B[0;32m--> 364\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43membed_with_retry\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    365\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    366\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokens\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m_chunk_size\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    367\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_invocation_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    368\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    369\u001B[0m     batched_embeddings\u001B[38;5;241m.\u001B[39mextend(r[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124membedding\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m r \u001B[38;5;129;01min\u001B[39;00m response[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    371\u001B[0m results: List[List[List[\u001B[38;5;28mfloat\u001B[39m]]] \u001B[38;5;241m=\u001B[39m [[] \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(texts))]\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/embeddings/openai.py:107\u001B[0m, in \u001B[0;36membed_with_retry\u001B[0;34m(embeddings, **kwargs)\u001B[0m\n\u001B[1;32m    104\u001B[0m     response \u001B[38;5;241m=\u001B[39m embeddings\u001B[38;5;241m.\u001B[39mclient\u001B[38;5;241m.\u001B[39mcreate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    105\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _check_response(response)\n\u001B[0;32m--> 107\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_embed_with_retry\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/tenacity/__init__.py:289\u001B[0m, in \u001B[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m    287\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(f)\n\u001B[1;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_f\u001B[39m(\u001B[38;5;241m*\u001B[39margs: t\u001B[38;5;241m.\u001B[39mAny, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: t\u001B[38;5;241m.\u001B[39mAny) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m t\u001B[38;5;241m.\u001B[39mAny:\n\u001B[0;32m--> 289\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/tenacity/__init__.py:389\u001B[0m, in \u001B[0;36mRetrying.__call__\u001B[0;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoSleep):\n\u001B[1;32m    388\u001B[0m     retry_state\u001B[38;5;241m.\u001B[39mprepare_for_next_attempt()\n\u001B[0;32m--> 389\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    390\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    391\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m do\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/tenacity/nap.py:31\u001B[0m, in \u001B[0;36msleep\u001B[0;34m(seconds)\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msleep\u001B[39m(seconds: \u001B[38;5;28mfloat\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     26\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;124;03m    Sleep strategy that delays execution for a given number of seconds.\u001B[39;00m\n\u001B[1;32m     28\u001B[0m \n\u001B[1;32m     29\u001B[0m \u001B[38;5;124;03m    This is the default strategy, and may be mocked out for unit testing.\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 31\u001B[0m     \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseconds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "openai_embeddings_vector_db = FAISS.from_documents(chunks, openai_azure_embeddings)\n",
    "openai_embeddings_vector_db.save_local(\"linux_kernel_openai_embeddings\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "question = \"What is the purpose of the get_user_page in the linux kernel?\"\n",
    "retrieved_chunks = hf_embeddings_vector_db.similarity_search(question)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "wizardcoder_15b = FastChatLLM(\n",
    "    model_host='model.llm.com',\n",
    "    fastchat_url='http://20.246.192.153',\n",
    "    base_model_name='WizardLM/WizardCoder-15B-V1.0'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "gpt35_azure_llm = AzureChatOpenAI(\n",
    "    temperature=0,\n",
    "    openai_api_key=\"02e3dbabaf334ccb959cbeadbd3f99c3\",\n",
    "    openai_api_base=\"https://llm-x-gpt.openai.azure.com/\",\n",
    "    deployment_name='LLM-X-GPT35-TURBO',\n",
    "    openai_api_version=\"2023-03-15-preview\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "gpt4_azure_llm = AzureChatOpenAI(\n",
    "    temperature=0,\n",
    "    openai_api_key=\"a8d69f68a36b40789df2cc3fdbaacda9\",\n",
    "    openai_api_base=\"https://llmx-gpt-canada-east.openai.azure.com/\",\n",
    "    deployment_name='LLM-X-GPT-4',\n",
    "    openai_api_version=\"2023-03-15-preview\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "502 Server Error: Bad Gateway for url: http://20.246.192.153/",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mHTTPError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 6\u001B[0m\n\u001B[1;32m      1\u001B[0m qa_rag_chain \u001B[38;5;241m=\u001B[39m RetrievalQA\u001B[38;5;241m.\u001B[39mfrom_chain_type(\n\u001B[1;32m      2\u001B[0m     llm\u001B[38;5;241m=\u001B[39mwizardcoder_15b,\n\u001B[1;32m      3\u001B[0m     retriever\u001B[38;5;241m=\u001B[39mhf_embeddings_vector_db\u001B[38;5;241m.\u001B[39mas_retriever()\n\u001B[1;32m      4\u001B[0m )\n\u001B[0;32m----> 6\u001B[0m \u001B[43mqa_rag_chain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mquery\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mquestion\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/chains/base.py:258\u001B[0m, in \u001B[0;36mChain.__call__\u001B[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001B[0m\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    257\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n\u001B[0;32m--> 258\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    259\u001B[0m run_manager\u001B[38;5;241m.\u001B[39mon_chain_end(outputs)\n\u001B[1;32m    260\u001B[0m final_outputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(\n\u001B[1;32m    261\u001B[0m     inputs, outputs, return_only_outputs\n\u001B[1;32m    262\u001B[0m )\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/chains/base.py:252\u001B[0m, in \u001B[0;36mChain.__call__\u001B[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001B[0m\n\u001B[1;32m    246\u001B[0m run_manager \u001B[38;5;241m=\u001B[39m callback_manager\u001B[38;5;241m.\u001B[39mon_chain_start(\n\u001B[1;32m    247\u001B[0m     dumpd(\u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    248\u001B[0m     inputs,\n\u001B[1;32m    249\u001B[0m )\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 252\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    253\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[1;32m    254\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(inputs)\n\u001B[1;32m    255\u001B[0m     )\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    257\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/chains/retrieval_qa/base.py:140\u001B[0m, in \u001B[0;36mBaseRetrievalQA._call\u001B[0;34m(self, inputs, run_manager)\u001B[0m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    139\u001B[0m     docs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_docs(question)  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 140\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcombine_documents_chain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_documents\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdocs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquestion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquestion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_run_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    142\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_source_documents:\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_key: answer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource_documents\u001B[39m\u001B[38;5;124m\"\u001B[39m: docs}\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/chains/base.py:456\u001B[0m, in \u001B[0;36mChain.run\u001B[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001B[0m\n\u001B[1;32m    451\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m(args[\u001B[38;5;241m0\u001B[39m], callbacks\u001B[38;5;241m=\u001B[39mcallbacks, tags\u001B[38;5;241m=\u001B[39mtags, metadata\u001B[38;5;241m=\u001B[39mmetadata)[\n\u001B[1;32m    452\u001B[0m         _output_key\n\u001B[1;32m    453\u001B[0m     ]\n\u001B[1;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args:\n\u001B[0;32m--> 456\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadata\u001B[49m\u001B[43m)\u001B[49m[\n\u001B[1;32m    457\u001B[0m         _output_key\n\u001B[1;32m    458\u001B[0m     ]\n\u001B[1;32m    460\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kwargs \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m args:\n\u001B[1;32m    461\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    462\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`run` supported with either positional arguments or keyword arguments,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    463\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m but none were provided.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    464\u001B[0m     )\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/chains/base.py:258\u001B[0m, in \u001B[0;36mChain.__call__\u001B[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001B[0m\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    257\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n\u001B[0;32m--> 258\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    259\u001B[0m run_manager\u001B[38;5;241m.\u001B[39mon_chain_end(outputs)\n\u001B[1;32m    260\u001B[0m final_outputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(\n\u001B[1;32m    261\u001B[0m     inputs, outputs, return_only_outputs\n\u001B[1;32m    262\u001B[0m )\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/chains/base.py:252\u001B[0m, in \u001B[0;36mChain.__call__\u001B[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001B[0m\n\u001B[1;32m    246\u001B[0m run_manager \u001B[38;5;241m=\u001B[39m callback_manager\u001B[38;5;241m.\u001B[39mon_chain_start(\n\u001B[1;32m    247\u001B[0m     dumpd(\u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    248\u001B[0m     inputs,\n\u001B[1;32m    249\u001B[0m )\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 252\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    253\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[1;32m    254\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(inputs)\n\u001B[1;32m    255\u001B[0m     )\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    257\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/chains/combine_documents/base.py:106\u001B[0m, in \u001B[0;36mBaseCombineDocumentsChain._call\u001B[0;34m(self, inputs, run_manager)\u001B[0m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;66;03m# Other keys are assumed to be needed for LLM prediction\u001B[39;00m\n\u001B[1;32m    105\u001B[0m other_keys \u001B[38;5;241m=\u001B[39m {k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m inputs\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minput_key}\n\u001B[0;32m--> 106\u001B[0m output, extra_return_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcombine_docs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    107\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdocs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_run_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mother_keys\u001B[49m\n\u001B[1;32m    108\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    109\u001B[0m extra_return_dict[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_key] \u001B[38;5;241m=\u001B[39m output\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m extra_return_dict\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/chains/combine_documents/stuff.py:165\u001B[0m, in \u001B[0;36mStuffDocumentsChain.combine_docs\u001B[0;34m(self, docs, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m    163\u001B[0m inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_inputs(docs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    164\u001B[0m \u001B[38;5;66;03m# Call predict on the LLM.\u001B[39;00m\n\u001B[0;32m--> 165\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mllm_chain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m, {}\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/chains/llm.py:252\u001B[0m, in \u001B[0;36mLLMChain.predict\u001B[0;34m(self, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m    237\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, callbacks: Callbacks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mstr\u001B[39m:\n\u001B[1;32m    238\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001B[39;00m\n\u001B[1;32m    239\u001B[0m \n\u001B[1;32m    240\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001B[39;00m\n\u001B[1;32m    251\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 252\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput_key]\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/chains/base.py:258\u001B[0m, in \u001B[0;36mChain.__call__\u001B[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001B[0m\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    257\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n\u001B[0;32m--> 258\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    259\u001B[0m run_manager\u001B[38;5;241m.\u001B[39mon_chain_end(outputs)\n\u001B[1;32m    260\u001B[0m final_outputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(\n\u001B[1;32m    261\u001B[0m     inputs, outputs, return_only_outputs\n\u001B[1;32m    262\u001B[0m )\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/chains/base.py:252\u001B[0m, in \u001B[0;36mChain.__call__\u001B[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001B[0m\n\u001B[1;32m    246\u001B[0m run_manager \u001B[38;5;241m=\u001B[39m callback_manager\u001B[38;5;241m.\u001B[39mon_chain_start(\n\u001B[1;32m    247\u001B[0m     dumpd(\u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    248\u001B[0m     inputs,\n\u001B[1;32m    249\u001B[0m )\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 252\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    253\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[1;32m    254\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(inputs)\n\u001B[1;32m    255\u001B[0m     )\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    257\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/chains/llm.py:92\u001B[0m, in \u001B[0;36mLLMChain._call\u001B[0;34m(self, inputs, run_manager)\u001B[0m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call\u001B[39m(\n\u001B[1;32m     88\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     89\u001B[0m     inputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any],\n\u001B[1;32m     90\u001B[0m     run_manager: Optional[CallbackManagerForChainRun] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     91\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[0;32m---> 92\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcreate_outputs(response)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/chains/llm.py:102\u001B[0m, in \u001B[0;36mLLMChain.generate\u001B[0;34m(self, input_list, run_manager)\u001B[0m\n\u001B[1;32m    100\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Generate LLM result from inputs.\"\"\"\u001B[39;00m\n\u001B[1;32m    101\u001B[0m prompts, stop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_prompts(input_list, run_manager\u001B[38;5;241m=\u001B[39mrun_manager)\n\u001B[0;32m--> 102\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mllm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    103\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    104\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    105\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    106\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mllm_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    107\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/llms/base.py:455\u001B[0m, in \u001B[0;36mBaseLLM.generate_prompt\u001B[0;34m(self, prompts, stop, callbacks, **kwargs)\u001B[0m\n\u001B[1;32m    447\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgenerate_prompt\u001B[39m(\n\u001B[1;32m    448\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    449\u001B[0m     prompts: List[PromptValue],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    452\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    453\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[1;32m    454\u001B[0m     prompt_strings \u001B[38;5;241m=\u001B[39m [p\u001B[38;5;241m.\u001B[39mto_string() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[0;32m--> 455\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_strings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/llms/base.py:586\u001B[0m, in \u001B[0;36mBaseLLM.generate\u001B[0;34m(self, prompts, stop, callbacks, tags, metadata, **kwargs)\u001B[0m\n\u001B[1;32m    577\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    578\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    579\u001B[0m         )\n\u001B[1;32m    580\u001B[0m     run_managers \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m    581\u001B[0m         callback_manager\u001B[38;5;241m.\u001B[39mon_llm_start(\n\u001B[1;32m    582\u001B[0m             dumpd(\u001B[38;5;28mself\u001B[39m), [prompt], invocation_params\u001B[38;5;241m=\u001B[39mparams, options\u001B[38;5;241m=\u001B[39moptions\n\u001B[1;32m    583\u001B[0m         )[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    584\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m callback_manager, prompt \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(callback_managers, prompts)\n\u001B[1;32m    585\u001B[0m     ]\n\u001B[0;32m--> 586\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate_helper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    587\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mbool\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mnew_arg_supported\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    588\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    589\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n\u001B[1;32m    590\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(missing_prompts) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/llms/base.py:492\u001B[0m, in \u001B[0;36mBaseLLM._generate_helper\u001B[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001B[0m\n\u001B[1;32m    490\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m run_manager \u001B[38;5;129;01min\u001B[39;00m run_managers:\n\u001B[1;32m    491\u001B[0m         run_manager\u001B[38;5;241m.\u001B[39mon_llm_error(e)\n\u001B[0;32m--> 492\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    493\u001B[0m flattened_outputs \u001B[38;5;241m=\u001B[39m output\u001B[38;5;241m.\u001B[39mflatten()\n\u001B[1;32m    494\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m manager, flattened_output \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(run_managers, flattened_outputs):\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/llms/base.py:479\u001B[0m, in \u001B[0;36mBaseLLM._generate_helper\u001B[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001B[0m\n\u001B[1;32m    469\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_generate_helper\u001B[39m(\n\u001B[1;32m    470\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    471\u001B[0m     prompts: List[\u001B[38;5;28mstr\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    475\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    476\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m LLMResult:\n\u001B[1;32m    477\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    478\u001B[0m         output \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 479\u001B[0m             \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    480\u001B[0m \u001B[43m                \u001B[49m\u001B[43mprompts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    481\u001B[0m \u001B[43m                \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    482\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;66;43;03m# TODO: support multiple run managers\u001B[39;49;00m\n\u001B[1;32m    483\u001B[0m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    484\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    485\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    486\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[1;32m    487\u001B[0m             \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate(prompts, stop\u001B[38;5;241m=\u001B[39mstop)\n\u001B[1;32m    488\u001B[0m         )\n\u001B[1;32m    489\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    490\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m run_manager \u001B[38;5;129;01min\u001B[39;00m run_managers:\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/llms/base.py:967\u001B[0m, in \u001B[0;36mLLM._generate\u001B[0;34m(self, prompts, stop, run_manager, **kwargs)\u001B[0m\n\u001B[1;32m    962\u001B[0m new_arg_supported \u001B[38;5;241m=\u001B[39m inspect\u001B[38;5;241m.\u001B[39msignature(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call)\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    963\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m prompt \u001B[38;5;129;01min\u001B[39;00m prompts:\n\u001B[1;32m    964\u001B[0m     text \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    965\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(prompt, stop\u001B[38;5;241m=\u001B[39mstop, run_manager\u001B[38;5;241m=\u001B[39mrun_manager, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    966\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[0;32m--> 967\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    968\u001B[0m     )\n\u001B[1;32m    969\u001B[0m     generations\u001B[38;5;241m.\u001B[39mappend([Generation(text\u001B[38;5;241m=\u001B[39mtext)])\n\u001B[1;32m    970\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m LLMResult(generations\u001B[38;5;241m=\u001B[39mgenerations)\n",
      "File \u001B[0;32m/tmp/pycharm_project_283/src/language_model_handlers/fastchat_llm.py:46\u001B[0m, in \u001B[0;36mFastChatLLM._call\u001B[0;34m(self, query, **kwargs)\u001B[0m\n\u001B[1;32m     44\u001B[0m request_body \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_request_body(query)\n\u001B[1;32m     45\u001B[0m response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mpost(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fastchat_url, headers\u001B[38;5;241m=\u001B[39mrequest_headers, json\u001B[38;5;241m=\u001B[39mrequest_body)\n\u001B[0;32m---> 46\u001B[0m \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# ToDo: Is this necessary?\u001B[39;00m\n\u001B[1;32m     47\u001B[0m response_text \u001B[38;5;241m=\u001B[39m _get_model_response_from_stream(response)\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response_text\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/requests/models.py:1021\u001B[0m, in \u001B[0;36mResponse.raise_for_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1016\u001B[0m     http_error_msg \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   1017\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstatus_code\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Server Error: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mreason\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for url: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39murl\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1018\u001B[0m     )\n\u001B[1;32m   1020\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m http_error_msg:\n\u001B[0;32m-> 1021\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HTTPError(http_error_msg, response\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[0;31mHTTPError\u001B[0m: 502 Server Error: Bad Gateway for url: http://20.246.192.153/"
     ]
    }
   ],
   "source": [
    "qa_rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=wizardcoder_15b,\n",
    "    retriever=hf_embeddings_vector_db.as_retriever()\n",
    ")\n",
    "\n",
    "qa_rag_chain({\"query\": question})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['What is the purpose of the get_user_page function in the Linux kernel?\\r', 'What is the purpose of the get_user_page function in the Linux kernel?\\r', 'What is the purpose of the get_user_page function in the Linux kernel?']\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig()\n",
    "logging.getLogger('langchain.retrievers.multi_query').setLevel(logging.INFO)\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=hf_embeddings_vector_db.as_retriever(),\n",
    "    llm=wizardcoder_15b\n",
    ")\n",
    "\n",
    "unique_docs = retriever_from_llm.get_relevant_documents(query=question)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def create_qna_GT_df(docs: List[Document], num_of_qna_for_doc: int) -> pd.DataFrame:\n",
    "    documents_cpp_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "        language=Language.CPP, chunk_size=4000, chunk_overlap=150\n",
    "    )\n",
    "    splitted_docs = documents_cpp_splitter.split_documents(docs)\n",
    "\n",
    "    multi_qa_prompt = PromptTemplate.from_template(template=MULTI_QA_GPT4_PROMPT_TEMPLATE,\n",
    "                                                   partial_variables={\"k\": num_of_qna_for_doc})\n",
    "    qa_generation_chain = QAGenerationChain.from_llm(llm=gpt4_azure_llm,\n",
    "                                                     prompt=multi_qa_prompt,\n",
    "                                                     text_splitter=documents_cpp_splitter)\n",
    "\n",
    "    qna_GT = []\n",
    "    for splitted_doc in tqdm(splitted_docs):\n",
    "        try:\n",
    "            qna = qa_generation_chain.run(splitted_doc.page_content)[INDEX_OF_FIRST_QNA_IN_RESPONSE]\n",
    "            qna_GT += qna\n",
    "        except JSONDecodeError:\n",
    "            print(\"Failed to generate valid QnA JSON for doc\")\n",
    "\n",
    "    qna_GT_df = pd.DataFrame(qna_GT)\n",
    "    return qna_GT_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def get_qna_with_chain_answers_df(qa_rag_chain: RetrievalQA, qna_GT_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    qna_with_chain_answers = qna_GT_df.copy()\n",
    "    qna_with_chain_answers[\"chain_answer\"] = qna_with_chain_answers.apply(\n",
    "        lambda qna: qa_rag_chain({\"query\": qna[\"question\"]})[\"result\"], axis=1)\n",
    "\n",
    "    return qna_with_chain_answers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def get_evaluator_score(evaluator: StringEvaluator, qna_with_chain_answer: pd.Series) -> float:\n",
    "    grade = evaluator.evaluate_strings(\n",
    "        prediction=qna_with_chain_answer[\"chain_answer\"],\n",
    "        reference=qna_with_chain_answer[\"answer\"],\n",
    "        input=qna_with_chain_answer[\"question\"])\n",
    "\n",
    "    return grade[\"score\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def get_retrieval_score(retriever, qna_with_chain_answer: pd.Series):\n",
    "    GRADE_DOCS_PROMPT = PromptTemplate(input_variables=['result', 'answer', 'query'],\n",
    "                                       template=GRADE_DOCS_PROMPT_TEMPLATE)\n",
    "    retrieval_eval_chain = load_evaluator(\n",
    "        evaluator=EvaluatorType.QA,\n",
    "        llm=gpt35_azure_llm,\n",
    "        prompt=GRADE_DOCS_PROMPT\n",
    "    )\n",
    "\n",
    "    retrieved_docs = retriever.get_relevant_documents(query=qna_with_chain_answer[\"question\"],\n",
    "                                                      search_type=\"similarity_score_threshold\",\n",
    "                                                      search_kwargs={\"k\": 2})\n",
    "\n",
    "    grade = retrieval_eval_chain.evaluate_strings(\n",
    "        prediction=retrieved_docs,\n",
    "        reference=qna_with_chain_answer[\"answer\"],\n",
    "        input=qna_with_chain_answer[\"question\"])\n",
    "\n",
    "    return grade[\"score\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def _fix_embedding_distance_evaluator_score(score: float) -> float:\n",
    "    return round(1 - score, 3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def get_grades_for_chain_qna(qna_with_chain_answers_df: pd.DataFrame,\n",
    "                             retriever: BaseRetriever = None) -> pd.DataFrame:\n",
    "    grades_for_chain_qna = qna_with_chain_answers_df.copy()\n",
    "\n",
    "    labeled_criteria_evaluator = load_evaluator(evaluator=EvaluatorType.LABELED_CRITERIA,\n",
    "                                                criteria=\"correctness\",\n",
    "                                                llm=gpt35_azure_llm)\n",
    "\n",
    "    embedding_distance_evaluator = load_evaluator(evaluator=EvaluatorType.EMBEDDING_DISTANCE,\n",
    "                                                  distance_metric=EmbeddingDistance.COSINE,\n",
    "                                                  embeddings=hf_embeddings,\n",
    "                                                  llm=gpt35_azure_llm)\n",
    "\n",
    "    qa_llm_jugde_evaluator = load_evaluator(evaluator=EvaluatorType.QA,\n",
    "                                            llm=gpt35_azure_llm)\n",
    "\n",
    "    grades_for_chain_qna[\"labeled_criteria_grades\"] = qna_with_chain_answers_df.apply(\n",
    "        lambda qna_with_chain_answer: get_evaluator_score(\n",
    "            evaluator=labeled_criteria_evaluator,\n",
    "            qna_with_chain_answer=qna_with_chain_answer), axis=1)\n",
    "\n",
    "    grades_for_chain_qna[\"qa_llm_jugde_grades\"] = qna_with_chain_answers_df.apply(\n",
    "        lambda qna_with_chain_answer: get_evaluator_score(\n",
    "            evaluator=qa_llm_jugde_evaluator,\n",
    "            qna_with_chain_answer=qna_with_chain_answer), axis=1)\n",
    "\n",
    "    grades_for_chain_qna[\"embedding_distance_grades\"] = qna_with_chain_answers_df.apply(\n",
    "        lambda qna_with_chain_answer: _fix_embedding_distance_evaluator_score(\n",
    "            get_evaluator_score(evaluator=embedding_distance_evaluator,\n",
    "                                qna_with_chain_answer=qna_with_chain_answer)), axis=1)\n",
    "\n",
    "    if retriever is not None:\n",
    "        grades_for_chain_qna[\"retrieval_score\"] = qna_with_chain_answers_df.apply(\n",
    "            lambda qna_with_chain_answer: get_retrieval_score(\n",
    "                retriever=retriever,\n",
    "                qna_with_chain_answer=qna_with_chain_answer), axis=1)\n",
    "\n",
    "    return grades_for_chain_qna"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def run_evaluation(qa_rag_chain: RetrievalQA, qna_GT_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    qna_with_chain_answers_df = get_qna_with_chain_answers_df(qa_rag_chain, qna_GT_df)\n",
    "    grades_for_chain_qna = \\\n",
    "        get_grades_for_chain_qna(qna_with_chain_answers_df=qna_with_chain_answers_df,\n",
    "                                 retriever=qa_rag_chain.retriever)\n",
    "    return grades_for_chain_qna"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watson/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/evaluation/schema.py:104: UserWarning: Ignoring input in EmbeddingDistanceEvalChain, as it is not expected.\n",
      "  warn(self._skip_input_warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                            question  \\\n0  What is the purpose of the 'for' loop in the g...   \n1  What does the variable 'fact' represent in the...   \n2             What is the purpose of the given code?   \n3    What is the return type of the 'fact' function?   \n4           What is the purpose of the code snippet?   \n5  What is the value of 'fact' after the code sni...   \n\n                                              answer  \\\n0  The 'for' loop is used to calculate the factor...   \n1  The variable 'fact' stores the factorial of th...   \n2  The purpose of the given code is to calculate ...   \n3   The return type of the 'fact' function is 'int'.   \n4  To calculate and display the factorial of a nu...   \n5    The factorial of the number entered by the user   \n\n                                        chain_answer  labeled_criteria_grades  \\\n0  The purpose of the 'for' loop in the given cod...                      NaN   \n1  In the given code, the variable 'fact' represe...                      1.0   \n2  The purpose of the given code is to input the ...                      NaN   \n3   The return type of the 'fact' function is 'int'.                      1.0   \n4  The purpose of the code snippet is to prompt t...                      NaN   \n5  The value of 'fact' cannot be determined witho...                      1.0   \n\n   embedding_distance_grades  qa_llm_jugde_grades  retrieval_score  \n0               3.103038e-01                    1              NaN  \n1               1.048536e-01                    1              1.0  \n2               6.754299e-01                    0              1.0  \n3              -2.220446e-16                    1              1.0  \n4               7.435595e-01                    0              NaN  \n5               5.335894e-01                    1              1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n      <th>chain_answer</th>\n      <th>labeled_criteria_grades</th>\n      <th>embedding_distance_grades</th>\n      <th>qa_llm_jugde_grades</th>\n      <th>retrieval_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is the purpose of the 'for' loop in the g...</td>\n      <td>The 'for' loop is used to calculate the factor...</td>\n      <td>The purpose of the 'for' loop in the given cod...</td>\n      <td>NaN</td>\n      <td>3.103038e-01</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What does the variable 'fact' represent in the...</td>\n      <td>The variable 'fact' stores the factorial of th...</td>\n      <td>In the given code, the variable 'fact' represe...</td>\n      <td>1.0</td>\n      <td>1.048536e-01</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What is the purpose of the given code?</td>\n      <td>The purpose of the given code is to calculate ...</td>\n      <td>The purpose of the given code is to input the ...</td>\n      <td>NaN</td>\n      <td>6.754299e-01</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What is the return type of the 'fact' function?</td>\n      <td>The return type of the 'fact' function is 'int'.</td>\n      <td>The return type of the 'fact' function is 'int'.</td>\n      <td>1.0</td>\n      <td>-2.220446e-16</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What is the purpose of the code snippet?</td>\n      <td>To calculate and display the factorial of a nu...</td>\n      <td>The purpose of the code snippet is to prompt t...</td>\n      <td>NaN</td>\n      <td>7.435595e-01</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>What is the value of 'fact' after the code sni...</td>\n      <td>The factorial of the number entered by the user</td>\n      <td>The value of 'fact' cannot be determined witho...</td>\n      <td>1.0</td>\n      <td>5.335894e-01</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_evaluation(qa_rag_chain=qa_rag_chain, qna_GT_df=qna_GT_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 24/258 [03:34<41:36, 10.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate valid QnA JSON for doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 51/258 [07:01<23:50,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate valid QnA JSON for doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 91/258 [11:58<24:41,  8.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate valid QnA JSON for doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 118/258 [15:14<17:30,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate valid QnA JSON for doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 135/258 [17:29<18:51,  9.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate valid QnA JSON for doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 170/258 [21:48<13:28,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate valid QnA JSON for doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 190/258 [24:36<08:56,  7.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate valid QnA JSON for doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 220/258 [28:38<05:00,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate valid QnA JSON for doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 235/258 [30:45<03:22,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate valid QnA JSON for doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|| 236/258 [30:52<03:02,  8.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate valid QnA JSON for doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 238/258 [31:13<03:03,  9.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to generate valid QnA JSON for doc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 258/258 [33:36<00:00,  7.82s/it]\n"
     ]
    }
   ],
   "source": [
    "# qna_GT_df = create_qna_GT_df(docs=docs, num_of_qna_for_doc=3)\n",
    "# qna_GT_df.to_csv(\"qna_GT_df.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'QAEvalChain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mQAEvalChain\u001B[49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'QAEvalChain' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "template = \"\"\"You are a teacher grading a quiz on the Linux kernel.\n",
    "You are given a question, the student's answer, and the true answer, and are asked to score the student answer as either CORRECT or INCORRECT.\n",
    "\n",
    "Example Format:\n",
    "QUESTION: question here\n",
    "STUDENT ANSWER: student's answer here\n",
    "TRUE ANSWER: true answer here\n",
    "GRADE: CORRECT or INCORRECT here\n",
    "\n",
    "Grade the student answers based ONLY on their factual accuracy. Ignore differences in punctuation and phrasing between the student answer and true answer. It is OK if the student answer contains more information than the true answer, as long as it does not contain any conflicting statements. Begin!\n",
    "\n",
    "QUESTION: {query}\n",
    "STUDENT ANSWER: {result}\n",
    "TRUE ANSWER: {answer}\n",
    "GRADE:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"query\", \"result\", \"answer\"], template=template\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "qna_GT_df = pd.read_csv(\"../qna_GT_df.csv\")\n",
    "partial_qna_GT_df = qna_GT_df[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "qna_with_chain_answers_df = get_qna_with_chain_answers_df(qa_rag_chain=qa_rag_chain,\n",
    "                                                          qna_GT_df=partial_qna_GT_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0 filename                                           question  \\\n0           0  filemap  What is the purpose of the file 'linux/mm/file...   \n1           1  filemap  What is the significance of the 'include' stat...   \n2           2  filemap  What does the function 'page_cache_delete' do ...   \n3           3  filemap  What does the function 'filemap_unaccount_foli...   \n4           4  filemap    What does the 'folio_test_hugetlb' function do?   \n\n                                              answer  \\\n0  The file 'linux/mm/filemap.c' handles the gene...   \n1  The 'include' statements are used to include v...   \n2  The function 'page_cache_delete' is not fully ...   \n3  The function 'filemap_unaccount_folio' is used...   \n4  The 'folio_test_hugetlb' function checks if th...   \n\n                                        chain_answer  \n0  The file 'linux/mm/filemap.c' contains the imp...  \n1  The 'include' statements in the 'linux/mm/file...  \n2  The `page_cache_delete` function is used to re...  \n3  The function 'filemap_unaccount_folio' is a he...  \n4  The 'folio_test_hugetlb' function checks if th...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>filename</th>\n      <th>question</th>\n      <th>answer</th>\n      <th>chain_answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>filemap</td>\n      <td>What is the purpose of the file 'linux/mm/file...</td>\n      <td>The file 'linux/mm/filemap.c' handles the gene...</td>\n      <td>The file 'linux/mm/filemap.c' contains the imp...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>filemap</td>\n      <td>What is the significance of the 'include' stat...</td>\n      <td>The 'include' statements are used to include v...</td>\n      <td>The 'include' statements in the 'linux/mm/file...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>filemap</td>\n      <td>What does the function 'page_cache_delete' do ...</td>\n      <td>The function 'page_cache_delete' is not fully ...</td>\n      <td>The `page_cache_delete` function is used to re...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>filemap</td>\n      <td>What does the function 'filemap_unaccount_foli...</td>\n      <td>The function 'filemap_unaccount_folio' is used...</td>\n      <td>The function 'filemap_unaccount_folio' is a he...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>filemap</td>\n      <td>What does the 'folio_test_hugetlb' function do?</td>\n      <td>The 'folio_test_hugetlb' function checks if th...</td>\n      <td>The 'folio_test_hugetlb' function checks if th...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_with_chain_answers_df"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
