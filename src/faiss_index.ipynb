{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import QAGenerationChain\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.evaluation import EmbeddingDistance\n",
    "from langchain.evaluation import load_evaluator, EvaluatorType\n",
    "from langchain.evaluation.schema import StringEvaluator\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.schema import BaseRetriever\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from src.prompt_templates import MULTI_QA_GPT35_PROMPT_TEMPLATE, GRADE_DOCS_PROMPT_TEMPLATE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# loader = TextLoader(\"../state_of_the_union.txt\")\n",
    "# documents = loader.load()\n",
    "# text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "# docs = text_splitter.split_documents(documents)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"../c-programs-master\"\n",
    "\n",
    "docs = []\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    for file in filenames:\n",
    "        if file.endswith(\".c\") and \"/.venv/\" not in dirpath:\n",
    "            try:\n",
    "                loader = TextLoader(os.path.join(dirpath, file), encoding=\"utf-8\")\n",
    "                docs.extend(loader.load())\n",
    "            except Exception as e:\n",
    "                pass\n",
    "print(f\"{len(docs)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    Language,\n",
    ")\n",
    "\n",
    "RecursiveCharacterTextSplitter.get_separators_for_language(Language.CPP)\n",
    "\n",
    "cpp_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.CPP, chunk_size=200, chunk_overlap=50\n",
    ")\n",
    "splitted_docs = cpp_splitter.split_documents(docs)\n",
    "print(f\"{len(splitted_docs)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "    model_kwargs={'device': 'cuda'},\n",
    "    encode_kwargs={'normalize_embeddings': False}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "hf_embeddings_vector_db = FAISS.from_documents(splitted_docs, hf_embeddings)\n",
    "hf_embeddings_vector_db.save_local(\"faiss_index\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "doc 0:\n",
      " for(i = 1; i <= n; i++){\n",
      "\t\tfact = fact * i;\t\n",
      "\t}\n",
      "\tprintf(\"Factorial of %d is = %d\", n, fact);\n",
      "\tgetch();\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "doc 1:\n",
      " // WAP to calculate factorial using recursion fucntion\n",
      "#include<stdio.h>\n",
      "int fact(int);\n",
      "\n",
      "\n",
      "\n",
      "doc 2:\n",
      " // WAP to calculate and display factorial of 5\n",
      "#include<stdio.h>\n",
      "main()\n",
      "{\n",
      "\tint i, n, fact=1;\n",
      "\tprintf(\"Enter a number for factorial:\\n\");\n",
      "\tscanf(\"%d\", &n);\n",
      "\tfor(i = 1; i <= n; i++){\n",
      "\t\tfact = fact * i;\n",
      "\n",
      "\n",
      "\n",
      "doc 3:\n",
      " void main()\n",
      "{\n",
      "\tint n, f;\n",
      "\tprintf(\"\\nEnter a number:\\n\");\n",
      "\tscanf(\"%d\", &n);\n",
      "\tf = fact(n);\n",
      "\tprintf(\"\\nfactorial of %d is %d\", n, f);\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "question = \"Where does factorial is being calculated?\"\n",
    "docs = hf_embeddings_vector_db.similarity_search(question)\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\n\\n\\ndoc {i}:\\n {doc.page_content}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "gpt35_azure_llm = AzureChatOpenAI(\n",
    "    temperature=0,\n",
    "    openai_api_key=\"02e3dbabaf334ccb959cbeadbd3f99c3\",\n",
    "    openai_api_base=\"https://llm-x-gpt.openai.azure.com/\",\n",
    "    deployment_name='LLM-X-GPT35-TURBO',\n",
    "    openai_api_version=\"2023-03-15-preview\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "gpt4_azure_llm = AzureChatOpenAI(\n",
    "    temperature=0,\n",
    "    openai_api_key=\"a8d69f68a36b40789df2cc3fdbaacda9\",\n",
    "    openai_api_base=\"https://llmx-gpt-canada-east.openai.azure.com/\",\n",
    "    deployment_name='LLM-X-GPT-4',\n",
    "    openai_api_version=\"2023-03-15-preview\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watson/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/embeddings/openai.py:214: UserWarning: WARNING! deployment_name is not default parameter.\n",
      "                    deployment_name was transferred to model_kwargs.\n",
      "                    Please confirm that deployment_name is what you intended.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "openai_azure_embeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=\"02e3dbabaf334ccb959cbeadbd3f99c3\",\n",
    "    openai_api_base=\"https://llm-x-gpt.openai.azure.com/\",\n",
    "    deployment_name='LLM-X-Embedding'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "{'query': 'How does factorial is calculated in the repository?',\n 'result': 'In the repository, there are three different ways to calculate the factorial of a number:\\n\\n1. Using a loop: The first method uses a for loop to iterate from 1 to the given number. Inside the loop, the factorial is calculated by multiplying the current value of the factorial variable with the loop counter. Finally, the factorial is printed.\\n\\n2. Using recursion: The second method defines a recursive function called \"fact\" that takes an integer as an argument. Inside the function, it checks if the given number is 0 or 1, in which case it returns 1. Otherwise, it calls itself recursively with the argument decremented by 1 and multiplies the result with the current number. The main function takes input from the user, calls the \"fact\" function, and prints the factorial.\\n\\n3. Using a loop with user input: The third method is similar to the first one, but it prompts the user to enter a number for which the factorial needs to be calculated. The input is stored in the variable \"n\", and the factorial is calculated using a for loop. Finally, the factorial is printed.'}"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=gpt35_azure_llm,\n",
    "    retriever=hf_embeddings_vector_db.as_retriever()\n",
    ")\n",
    "\n",
    "question = \"How does factorial is calculated in the repository?\"\n",
    "qa_rag_chain({\"query\": question})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. What is the method used to calculate factorial in the repository?', '2. Can you explain the process of calculating factorial in the repository?', '3. How is the factorial calculated within the repository?']\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig()\n",
    "logging.getLogger('langchain.retrievers.multi_query').setLevel(logging.INFO)\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=hf_embeddings_vector_db.as_retriever(),\n",
    "    llm=gpt35_azure_llm\n",
    ")\n",
    "\n",
    "unique_docs = retriever_from_llm.get_relevant_documents(query=question)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def create_qna_GT_df(docs: List[Document], num_of_qna_for_doc: int) -> pd.DataFrame:\n",
    "    multi_qa_prompt = PromptTemplate.from_template(template=MULTI_QA_GPT35_PROMPT_TEMPLATE,\n",
    "                                                   partial_variables={\"k\": num_of_qna_for_doc})\n",
    "    qa_generation_chain = QAGenerationChain.from_llm(llm=gpt35_azure_llm,\n",
    "                                                     prompt=multi_qa_prompt)\n",
    "\n",
    "    qna_GT = []\n",
    "    for doc in docs:\n",
    "        doc_qna = qa_generation_chain.run(doc.page_content)[0]\n",
    "        qna_GT += doc_qna\n",
    "\n",
    "    qna_GT_df = pd.DataFrame(qna_GT)\n",
    "    return qna_GT_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def get_qna_with_chain_answers_df(qa_rag_chain: RetrievalQA, qna_GT_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    qna_with_chain_answers = qna_GT_df.copy()\n",
    "    qna_with_chain_answers[\"chain_answer\"] = qna_with_chain_answers.apply(\n",
    "        lambda qna: qa_rag_chain({\"query\": qna[\"question\"]})[\"result\"], axis=1)\n",
    "\n",
    "    return qna_with_chain_answers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def get_evaluator_score(evaluator: StringEvaluator, qna_with_chain_answer: pd.Series) -> float:\n",
    "    grade = evaluator.evaluate_strings(\n",
    "        prediction=qna_with_chain_answer[\"chain_answer\"],\n",
    "        reference=qna_with_chain_answer[\"answer\"],\n",
    "        input=qna_with_chain_answer[\"question\"])\n",
    "\n",
    "    return grade[\"score\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def get_retrieval_score(retriever, qna_with_chain_answer: pd.Series):\n",
    "    GRADE_DOCS_PROMPT = PromptTemplate(input_variables=['result', 'answer', 'query'],\n",
    "                                       template=GRADE_DOCS_PROMPT_TEMPLATE)\n",
    "    retrieval_eval_chain = load_evaluator(\n",
    "        evaluator=EvaluatorType.QA,\n",
    "        llm=gpt35_azure_llm,\n",
    "        prompt=GRADE_DOCS_PROMPT\n",
    "    )\n",
    "\n",
    "    retrieved_docs = retriever.get_relevant_documents(query=qna_with_chain_answer[\"question\"],\n",
    "                                                      search_type=\"similarity_score_threshold\",\n",
    "                                                      search_kwargs={\"k\": 2})\n",
    "\n",
    "    grade = retrieval_eval_chain.evaluate_strings(\n",
    "        prediction=retrieved_docs,\n",
    "        reference=qna_with_chain_answer[\"answer\"],\n",
    "        input=qna_with_chain_answer[\"question\"])\n",
    "\n",
    "    return grade[\"score\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "def get_grades_for_chain_qna(qna_with_chain_answers_df: pd.DataFrame,\n",
    "                             retriever: BaseRetriever = None) -> pd.DataFrame:\n",
    "    grades_for_chain_qna = qna_with_chain_answers_df.copy()\n",
    "\n",
    "    labeled_criteria_evaluator = load_evaluator(evaluator=EvaluatorType.LABELED_CRITERIA,\n",
    "                                                criteria=\"correctness\",\n",
    "                                                llm=gpt35_azure_llm)\n",
    "\n",
    "    embedding_distance_evaluator = load_evaluator(evaluator=EvaluatorType.EMBEDDING_DISTANCE,\n",
    "                                                  distance_metric=EmbeddingDistance.COSINE,\n",
    "                                                  embeddings=hf_embeddings,\n",
    "                                                  llm=gpt35_azure_llm)\n",
    "\n",
    "    qa_llm_jugde_evaluator = load_evaluator(evaluator=EvaluatorType.QA,\n",
    "                                            llm=gpt35_azure_llm)\n",
    "\n",
    "    grades_for_chain_qna[\"labeled_criteria_grades\"] = qna_with_chain_answers_df.apply(\n",
    "        lambda qna_with_chain_answer: get_evaluator_score(\n",
    "            evaluator=labeled_criteria_evaluator,\n",
    "            qna_with_chain_answer=qna_with_chain_answer), axis=1)\n",
    "\n",
    "    grades_for_chain_qna[\"embedding_distance_grades\"] = qna_with_chain_answers_df.apply(\n",
    "        lambda qna_with_chain_answer: get_evaluator_score(\n",
    "            evaluator=embedding_distance_evaluator,\n",
    "            qna_with_chain_answer=qna_with_chain_answer), axis=1)\n",
    "\n",
    "    grades_for_chain_qna[\"qa_llm_jugde_grades\"] = qna_with_chain_answers_df.apply(\n",
    "        lambda qna_with_chain_answer: get_evaluator_score(\n",
    "            evaluator=qa_llm_jugde_evaluator,\n",
    "            qna_with_chain_answer=qna_with_chain_answer), axis=1)\n",
    "\n",
    "    if retriever:\n",
    "        grades_for_chain_qna[\"retrieval_score\"] = qna_with_chain_answers_df.apply(\n",
    "            lambda qna_with_chain_answer: get_retrieval_score(\n",
    "                retriever=retriever,\n",
    "                qna_with_chain_answer=qna_with_chain_answer), axis=1)\n",
    "\n",
    "    return grades_for_chain_qna"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def run_evaluation(qa_rag_chain: RetrievalQA, qna_GT_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    qna_with_chain_answers_df = get_qna_with_chain_answers_df(qa_rag_chain, qna_GT_df)\n",
    "    grades_for_chain_qna = \\\n",
    "        get_grades_for_chain_qna(qna_with_chain_answers_df=qna_with_chain_answers_df,\n",
    "                                 retriever=qa_rag_chain.retriever)\n",
    "    return grades_for_chain_qna"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "qna_GT_df = create_qna_GT_df(docs=docs[:3], num_of_qna_for_doc=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watson/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/evaluation/schema.py:104: UserWarning: Ignoring input in EmbeddingDistanceEvalChain, as it is not expected.\n",
      "  warn(self._skip_input_warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                            question  \\\n0  What is the purpose of the 'for' loop in the g...   \n1  What does the variable 'fact' represent in the...   \n2             What is the purpose of the given code?   \n3    What is the return type of the 'fact' function?   \n4           What is the purpose of the code snippet?   \n5  What is the value of 'fact' after the code sni...   \n\n                                              answer  \\\n0  The 'for' loop is used to calculate the factor...   \n1  The variable 'fact' stores the factorial of th...   \n2  The purpose of the given code is to calculate ...   \n3   The return type of the 'fact' function is 'int'.   \n4  To calculate and display the factorial of a nu...   \n5    The factorial of the number entered by the user   \n\n                                        chain_answer  labeled_criteria_grades  \\\n0  The purpose of the 'for' loop in the given cod...                      NaN   \n1  In the given code, the variable 'fact' represe...                      1.0   \n2  The purpose of the given code is to input the ...                      NaN   \n3   The return type of the 'fact' function is 'int'.                      1.0   \n4  The purpose of the code snippet is to prompt t...                      NaN   \n5  The value of 'fact' cannot be determined witho...                      1.0   \n\n   embedding_distance_grades  qa_llm_jugde_grades  retrieval_score  \n0               3.103038e-01                    1              NaN  \n1               1.048536e-01                    1              1.0  \n2               6.754299e-01                    0              1.0  \n3              -2.220446e-16                    1              1.0  \n4               7.435595e-01                    0              NaN  \n5               5.335894e-01                    1              1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n      <th>chain_answer</th>\n      <th>labeled_criteria_grades</th>\n      <th>embedding_distance_grades</th>\n      <th>qa_llm_jugde_grades</th>\n      <th>retrieval_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is the purpose of the 'for' loop in the g...</td>\n      <td>The 'for' loop is used to calculate the factor...</td>\n      <td>The purpose of the 'for' loop in the given cod...</td>\n      <td>NaN</td>\n      <td>3.103038e-01</td>\n      <td>1</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What does the variable 'fact' represent in the...</td>\n      <td>The variable 'fact' stores the factorial of th...</td>\n      <td>In the given code, the variable 'fact' represe...</td>\n      <td>1.0</td>\n      <td>1.048536e-01</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What is the purpose of the given code?</td>\n      <td>The purpose of the given code is to calculate ...</td>\n      <td>The purpose of the given code is to input the ...</td>\n      <td>NaN</td>\n      <td>6.754299e-01</td>\n      <td>0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What is the return type of the 'fact' function?</td>\n      <td>The return type of the 'fact' function is 'int'.</td>\n      <td>The return type of the 'fact' function is 'int'.</td>\n      <td>1.0</td>\n      <td>-2.220446e-16</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What is the purpose of the code snippet?</td>\n      <td>To calculate and display the factorial of a nu...</td>\n      <td>The purpose of the code snippet is to prompt t...</td>\n      <td>NaN</td>\n      <td>7.435595e-01</td>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>What is the value of 'fact' after the code sni...</td>\n      <td>The factorial of the number entered by the user</td>\n      <td>The value of 'fact' cannot be determined witho...</td>\n      <td>1.0</td>\n      <td>5.335894e-01</td>\n      <td>1</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_evaluation(qa_rag_chain=qa_rag_chain, qna_GT_df=qna_GT_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
