{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.evaluation import load_evaluator, EvaluatorType\n",
    "from langchain.evaluation import EmbeddingDistance\n",
    "from langchain.evaluation.schema import StringEvaluator\n",
    "from typing import List"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "loader = TextLoader(\"../state_of_the_union.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cuda'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "\n",
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "hf_embeddings_vector_db = FAISS.from_documents(docs, hf_embeddings)\n",
    "hf_embeddings_vector_db.save_local(\"faiss_index\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "'We’re going after the criminals who stole billions in relief money meant for small businesses and millions of Americans.  \\n\\nAnd tonight, I’m announcing that the Justice Department will name a chief prosecutor for pandemic fraud. \\n\\nBy the end of this year, the deficit will be down to less than half what it was before I took office.  \\n\\nThe only president ever to cut the deficit by more than one trillion dollars in a single year. \\n\\nLowering your costs also means demanding more competition. \\n\\nI’m a capitalist, but capitalism without competition isn’t capitalism. \\n\\nIt’s exploitation—and it drives up prices. \\n\\nWhen corporations don’t have to compete, their profits go up, your prices go up, and small businesses and family farmers and ranchers go under. \\n\\nWe see it happening with ocean carriers moving goods in and out of America. \\n\\nDuring the pandemic, these foreign-owned companies raised prices by as much as 1,000% and made record profits.'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What did the president say about economics?\"\n",
    "docs = hf_embeddings_vector_db.similarity_search(question)\n",
    "docs[0].page_content"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "gpt35_azure_llm = AzureChatOpenAI(\n",
    "    temperature=0,\n",
    "    openai_api_key=\"02e3dbabaf334ccb959cbeadbd3f99c3\",\n",
    "    openai_api_base=\"https://llm-x-gpt.openai.azure.com/\",\n",
    "    deployment_name='LLM-X-GPT35-TURBO',\n",
    "    openai_api_version=\"2023-03-15-preview\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "gpt4_azure_llm = AzureChatOpenAI(\n",
    "    temperature=0,\n",
    "    openai_api_key=\"a8d69f68a36b40789df2cc3fdbaacda9\",\n",
    "    openai_api_base=\"https://llmx-gpt-canada-east.openai.azure.com/\",\n",
    "    deployment_name='LLM-X-GPT-4',\n",
    "    openai_api_version=\"2023-03-15-preview\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "openai_azure_embeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=\"02e3dbabaf334ccb959cbeadbd3f99c3\",\n",
    "    openai_api_base=\"https://llm-x-gpt.openai.azure.com/\",\n",
    "    deployment_name='LLM-X-Embedding'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: [\"1. Can you provide any information on the president's statements regarding the field of economics?\", \"2. I'm interested in knowing the president's views and comments on the subject of economics. Could you share any relevant information?\", '3. Could you please share any insights or remarks made by the president in relation to economics?']\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig()\n",
    "logging.getLogger('langchain.retrievers.multi_query').setLevel(logging.INFO)\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=hf_embeddings_vector_db.as_retriever(),\n",
    "    llm=gpt35_azure_llm\n",
    ")\n",
    "\n",
    "unique_docs = retriever_from_llm.get_relevant_documents(query=question)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "{'query': 'What did the president say about Zelensky?',\n 'result': \"The president mentioned President Zelenskyy of Ukraine in the context of the Ukrainian people's resistance against Russia's invasion. He praised their fearlessness, courage, and determination, which he said inspires the world. However, he did not provide specific details about Zelenskyy's actions or policies.\"}"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=gpt4_azure_llm,\n",
    "    retriever=hf_embeddings_vector_db.as_retriever()\n",
    ")\n",
    "\n",
    "question = \"What did the president say about Zelensky?\"\n",
    "qa_rag_chain({\"query\": question})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "{'query': 'What did the president say about Zelensky?',\n 'result': 'The president mentioned President Zelenskyy of Ukraine and praised the fearlessness, courage, and determination of the Ukrainian people.'}"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=gpt35_azure_llm,\n",
    "    retriever=hf_embeddings_vector_db.as_retriever()\n",
    ")\n",
    "\n",
    "question = \"What did the president say about Zelensky?\"\n",
    "qa_rag_chain({\"query\": question})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from langchain.chains import QAGenerationChain\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "templ = \"\"\"You are a smart assistant designed to help high school teachers come up with reading comprehension questions.\n",
    "Given a piece of text, you must come up with a {k} different question and answer pairs that can be used to test a student's reading comprehension abilities.\n",
    "When coming up with this question/answer pair, each pair must be respond in the following format:\n",
    "\n",
    "{{\n",
    "    \"question\": \"$YOUR_QUESTION_HERE\",\n",
    "    \"answer\": \"$THE_ANSWER_HERE\"\n",
    "}}\n",
    "\n",
    "So in your final answer you should response with a list of {k} pairs in this format:\n",
    "\n",
    "```\n",
    "[{{\n",
    "    \"question\": \"$YOUR_QUESTION_HERE\",\n",
    "    \"answer\": \"$THE_ANSWER_HERE\"\n",
    "}},\n",
    " {{\n",
    "    \"question\": \"$YOUR_QUESTION_HERE\",\n",
    "    \"answer\": \"$THE_ANSWER_HERE\"\n",
    "}},\n",
    " {{\n",
    "    \"question\": \"$YOUR_QUESTION_HERE\",\n",
    "    \"answer\": \"$THE_ANSWER_HERE\"\n",
    "    }}\n",
    "]\n",
    "```\n",
    "\n",
    "Please come up with a list of {k} question/answer pairs, in the specified list of JSONS format, for the following text:\n",
    "----------------\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "multi_qa_prompt_gpt35 = PromptTemplate.from_template(template=templ, partial_variables={\"k\": 5})\n",
    "qa_generation_chain_gpt35 = QAGenerationChain.from_llm(llm=gpt35_azure_llm, prompt=multi_qa_prompt_gpt35)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from langchain.chains import QAGenerationChain\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "templ = \"\"\"You are a smart assistant designed to help high school teachers come up with reading comprehension questions.\n",
    "Given a piece of text, you must come up with a {k} different question and answer pairs that can be used to test a student's reading comprehension abilities.\n",
    "When coming up with this question/answer pair, each pair must be respond in the following format:\n",
    "\n",
    "{{\n",
    "    \"question\": \"$YOUR_QUESTION_HERE\",\n",
    "    \"answer\": \"$THE_ANSWER_HERE\"\n",
    "}}\n",
    "Please come up with a list of {k} question/answer pairs, in the specified list of dict, for the following text:\n",
    "----------------\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "multi_qa_prompt = PromptTemplate.from_template(template=templ, partial_variables={\"k\": 5})\n",
    "qa_generation_chain = QAGenerationChain.from_llm(llm=gpt4_azure_llm, prompt=multi_qa_prompt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'question': 'What action is being taken against the criminals who stole relief money?',\n  'answer': 'The Justice Department will name a chief prosecutor for pandemic fraud.'},\n {'question': 'What will be the state of the deficit by the end of the year?',\n  'answer': 'By the end of this year, the deficit will be down to less than half what it was before the speaker took office.'},\n {'question': \"What is the speaker's view on capitalism without competition?\",\n  'answer': \"The speaker believes that capitalism without competition isn't capitalism, but exploitation.\"},\n {'question': \"What happens when corporations don't have to compete?\",\n  'answer': 'When corporations don’t have to compete, their profits go up, prices go up, and small businesses and family farmers and ranchers go under.'},\n {'question': 'What did foreign-owned companies do during the pandemic?',\n  'answer': 'During the pandemic, these foreign-owned companies raised prices by as much as 1,000% and made record profits.'}]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_GT = qa_generation_chain.run(docs[0].page_content)[0]\n",
    "qna_GT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def get_qna_with_chain_answers_df(qa_rag_chain, qna_GT) -> pd.DataFrame:\n",
    "    qna_with_chain_answers = []\n",
    "\n",
    "    for qna in qna_GT:\n",
    "        question, answer = qna[\"question\"], qna[\"answer\"]\n",
    "        chain_answer = qa_rag_chain({\"query\": question})[\"result\"]\n",
    "        qna_with_chain_answers.append({\"question\": question,\n",
    "                                       \"answer\": answer,\n",
    "                                       \"chain_answer\": chain_answer})\n",
    "\n",
    "    qna_with_chain_answers_df = pd.DataFrame(qna_with_chain_answers)\n",
    "    return qna_with_chain_answers_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_evaluator_score(evaluator: StringEvaluator, qna_with_chain_answer: pd.Series) -> float:\n",
    "    grade = evaluator.evaluate_strings(\n",
    "        prediction=qna_with_chain_answer[\"chain_answer\"],\n",
    "        reference=qna_with_chain_answer[\"answer\"],\n",
    "        input=qna_with_chain_answer[\"question\"])\n",
    "\n",
    "    return grade[\"score\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def get_grades_for_chain_qna(qna_with_chain_answers_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    grades_for_chain_qna = qna_with_chain_answers_df.copy()\n",
    "\n",
    "    labeled_criteria_evaluator = load_evaluator(evaluator=EvaluatorType.LABELED_CRITERIA,\n",
    "                                                criteria=\"correctness\",\n",
    "                                                llm=gpt4_azure_llm)\n",
    "\n",
    "    embedding_distance_evaluator = load_evaluator(evaluator=EvaluatorType.EMBEDDING_DISTANCE,\n",
    "                                                        distance_metric=EmbeddingDistance.COSINE,\n",
    "                                                        embeddings=hf_embeddings,\n",
    "                                                        llm=gpt4_azure_llm)\n",
    "\n",
    "    qa_llm__jugde_evaluator = load_evaluator(evaluator=EvaluatorType.QA,\n",
    "                                      llm=gpt4_azure_llm)\n",
    "\n",
    "    grades_for_chain_qna[\"labeled_criteria_grades\"] = qna_with_chain_answers_df.apply(\n",
    "            lambda qna_with_chain_answer: get_evaluator_score(\n",
    "                evaluator=labeled_criteria_evaluator,\n",
    "                qna_with_chain_answer=qna_with_chain_answer),\n",
    "        axis=1)\n",
    "\n",
    "    grades_for_chain_qna[\"embedding_distance_grades\"] = qna_with_chain_answers_df.apply(\n",
    "            lambda qna_with_chain_answer: get_evaluator_score(\n",
    "                evaluator=embedding_distance_evaluator,\n",
    "                qna_with_chain_answer=qna_with_chain_answer),\n",
    "        axis=1)\n",
    "\n",
    "    grades_for_chain_qna[\"qa_llm_jugde_grades\"] = qna_with_chain_answers_df.apply(\n",
    "            lambda qna_with_chain_answer: get_evaluator_score(\n",
    "                evaluator=qa_llm__jugde_evaluator,\n",
    "                qna_with_chain_answer=qna_with_chain_answer),\n",
    "        axis=1)\n",
    "\n",
    "    return grades_for_chain_qna"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "def run_evaluation(qa_rag_chain: RetrievalQA, qna_GT: List) -> pd.DataFrame:\n",
    "    qna_with_chain_answers_df = get_qna_with_chain_answers_df(qa_rag_chain, qna_GT)\n",
    "    grades_for_chain_qna = get_grades_for_chain_qna(qna_with_chain_answers_df)\n",
    "    return grades_for_chain_qna"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/watson/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/evaluation/schema.py:104: UserWarning: Ignoring input in EmbeddingDistanceEvalChain, as it is not expected.\n",
      "  warn(self._skip_input_warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                            question  \\\n0  What action is being taken against the crimina...   \n1  What will be the state of the deficit by the e...   \n2  What is the speaker's view on capitalism witho...   \n3  What happens when corporations don't have to c...   \n4  What did foreign-owned companies do during the...   \n\n                                              answer  \\\n0  The Justice Department will name a chief prose...   \n1  By the end of this year, the deficit will be d...   \n2  The speaker believes that capitalism without c...   \n3  When corporations don’t have to compete, their...   \n4  During the pandemic, these foreign-owned compa...   \n\n                                        chain_answer  labeled_criteria_grades  \\\n0  The Justice Department is naming a chief prose...                        1   \n1                     I don't have that information.                        0   \n2  The speaker's view is that capitalism without ...                        1   \n3  When corporations don't have to compete, their...                        1   \n4  During the pandemic, foreign-owned companies r...                        1   \n\n   embedding_distance_grades  qa_llm_jugde_grades  \n0                   0.085530                    1  \n1                   0.987754                    0  \n2                   0.130067                    1  \n3                   0.218570                    1  \n4                   0.009678                    1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n      <th>chain_answer</th>\n      <th>labeled_criteria_grades</th>\n      <th>embedding_distance_grades</th>\n      <th>qa_llm_jugde_grades</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What action is being taken against the crimina...</td>\n      <td>The Justice Department will name a chief prose...</td>\n      <td>The Justice Department is naming a chief prose...</td>\n      <td>1</td>\n      <td>0.085530</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What will be the state of the deficit by the e...</td>\n      <td>By the end of this year, the deficit will be d...</td>\n      <td>I don't have that information.</td>\n      <td>0</td>\n      <td>0.987754</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>What is the speaker's view on capitalism witho...</td>\n      <td>The speaker believes that capitalism without c...</td>\n      <td>The speaker's view is that capitalism without ...</td>\n      <td>1</td>\n      <td>0.130067</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What happens when corporations don't have to c...</td>\n      <td>When corporations don’t have to compete, their...</td>\n      <td>When corporations don't have to compete, their...</td>\n      <td>1</td>\n      <td>0.218570</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What did foreign-owned companies do during the...</td>\n      <td>During the pandemic, these foreign-owned compa...</td>\n      <td>During the pandemic, foreign-owned companies r...</td>\n      <td>1</td>\n      <td>0.009678</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades_for_chain_qna = run_evaluation(qa_rag_chain, qna_GT)\n",
    "grades_for_chain_qna"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
