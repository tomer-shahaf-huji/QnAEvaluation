{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "from typing import List\n",
    "\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "loader = TextLoader(\"../state_of_the_union.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cuda'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "\n",
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "hf_embeddings_vector_db = FAISS.from_documents(docs, hf_embeddings)\n",
    "hf_embeddings_vector_db.save_local(\"faiss_index\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "'We’re going after the criminals who stole billions in relief money meant for small businesses and millions of Americans.  \\n\\nAnd tonight, I’m announcing that the Justice Department will name a chief prosecutor for pandemic fraud. \\n\\nBy the end of this year, the deficit will be down to less than half what it was before I took office.  \\n\\nThe only president ever to cut the deficit by more than one trillion dollars in a single year. \\n\\nLowering your costs also means demanding more competition. \\n\\nI’m a capitalist, but capitalism without competition isn’t capitalism. \\n\\nIt’s exploitation—and it drives up prices. \\n\\nWhen corporations don’t have to compete, their profits go up, your prices go up, and small businesses and family farmers and ranchers go under. \\n\\nWe see it happening with ocean carriers moving goods in and out of America. \\n\\nDuring the pandemic, these foreign-owned companies raised prices by as much as 1,000% and made record profits.'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What did the president say about economics?\"\n",
    "docs = hf_embeddings_vector_db.similarity_search(question)\n",
    "docs[0].page_content"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "gpt35_azure_llm = AzureChatOpenAI(\n",
    "    temperature=0,\n",
    "    openai_api_key=\"02e3dbabaf334ccb959cbeadbd3f99c3\",\n",
    "    openai_api_base=\"https://llm-x-gpt.openai.azure.com/\",\n",
    "    deployment_name='LLM-X-GPT35-TURBO',\n",
    "    openai_api_version=\"2023-03-15-preview\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "openai_azure_embeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=\"02e3dbabaf334ccb959cbeadbd3f99c3\",\n",
    "    openai_api_base=\"https://llm-x-gpt.openai.azure.com/\",\n",
    "    deployment_name='LLM-X-Embedding'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: [\"1. Can you provide any information on the president's statements regarding the field of economics?\", \"2. I'm interested in knowing the president's views and comments on the subject of economics. Could you share any relevant information?\", '3. Could you please share any insights or remarks made by the president in relation to economics?']\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig()\n",
    "logging.getLogger('langchain.retrievers.multi_query').setLevel(logging.INFO)\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=hf_embeddings_vector_db.as_retriever(),\n",
    "    llm=gpt35_azure_llm\n",
    ")\n",
    "\n",
    "unique_docs = retriever_from_llm.get_relevant_documents(query=question)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "{'query': 'What did the president say about Zelensky?',\n 'result': 'The president mentioned President Zelenskyy of Ukraine and praised the fearlessness, courage, and determination of the Ukrainian people.'}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=gpt35_azure_llm,\n",
    "    retriever=hf_embeddings_vector_db.as_retriever()\n",
    ")\n",
    "\n",
    "question = \"What did the president say about Zelensky?\"\n",
    "qa_rag_chain({\"query\": question})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from langchain.chains import QAGenerationChain\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "templ = \"\"\"You are a smart assistant designed to help high school teachers come up with reading comprehension questions.\n",
    "Given a piece of text, you must come up with a {k} different question and answer pairs that can be used to test a student's reading comprehension abilities.\n",
    "When coming up with this question/answer pair, each pair must be respond in the following format:\n",
    "\n",
    "{{\n",
    "    \"question\": \"$YOUR_QUESTION_HERE\",\n",
    "    \"answer\": \"$THE_ANSWER_HERE\"\n",
    "}}\n",
    "\n",
    "So in your final answer you should response with a list of {k} pairs in this format:\n",
    "\n",
    "```\n",
    "[{{\n",
    "    \"question\": \"$YOUR_QUESTION_HERE\",\n",
    "    \"answer\": \"$THE_ANSWER_HERE\"\n",
    "}},\n",
    " {{\n",
    "    \"question\": \"$YOUR_QUESTION_HERE\",\n",
    "    \"answer\": \"$THE_ANSWER_HERE\"\n",
    "}},\n",
    " {{\n",
    "    \"question\": \"$YOUR_QUESTION_HERE\",\n",
    "    \"answer\": \"$THE_ANSWER_HERE\"\n",
    "    }}\n",
    "]\n",
    "```\n",
    "\n",
    "Please come up with a list of {k} question/answer pairs, in the specified list of JSONS format, for the following text:\n",
    "----------------\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "multi_qa_prompt = PromptTemplate.from_template(template=templ, partial_variables={\"k\": 5})\n",
    "qa_generation_chain = QAGenerationChain.from_llm(llm=gpt35_azure_llm, prompt=multi_qa_prompt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'question': 'What is the purpose of the chief prosecutor for pandemic fraud?',\n  'answer': 'To go after the criminals who stole relief money meant for small businesses and Americans.'},\n {'question': 'How much will the deficit be reduced to by the end of this year?',\n  'answer': 'Less than half of what it was before the current president took office.'},\n {'question': \"What does the speaker mean by 'capitalism without competition isn't capitalism'?\",\n  'answer': 'The speaker believes that true capitalism requires competition, and without it, it becomes exploitation.'},\n {'question': \"What happens to prices when corporations don't have to compete?\",\n  'answer': 'Prices go up.'},\n {'question': 'What did foreign-owned ocean carriers do during the pandemic?',\n  'answer': 'They raised prices by as much as 1,000% and made record profits.'}]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_GT = qa_generation_chain.run(docs[0].page_content)[0]\n",
    "qna_GT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA number 1 \n",
      "\n",
      "Question: What is the purpose of the chief prosecutor for pandemic fraud?\n",
      "\n",
      "Answer: To go after the criminals who stole relief money meant for small businesses and Americans.\n",
      "\n",
      "LLM Answer: The purpose of the chief prosecutor for pandemic fraud is to go after the criminals who stole billions in relief money meant for small businesses and millions of Americans. They will be responsible for investigating and prosecuting cases of fraud related to the misuse of funds intended for pandemic relief.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "QA number 2 \n",
      "\n",
      "Question: How much will the deficit be reduced to by the end of this year?\n",
      "\n",
      "Answer: Less than half of what it was before the current president took office.\n",
      "\n",
      "LLM Answer: The given context does not provide specific information about the projected reduction of the deficit by the end of this year. Therefore, I don't have the information to answer your question.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "QA number 3 \n",
      "\n",
      "Question: What does the speaker mean by 'capitalism without competition isn't capitalism'?\n",
      "\n",
      "Answer: The speaker believes that true capitalism requires competition, and without it, it becomes exploitation.\n",
      "\n",
      "LLM Answer: The speaker means that true capitalism requires competition. Without competition, capitalism becomes exploitative and leads to higher prices for consumers. The speaker believes that when corporations don't have to compete, they can drive up prices, harm small businesses, and exploit consumers.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "QA number 4 \n",
      "\n",
      "Question: What happens to prices when corporations don't have to compete?\n",
      "\n",
      "Answer: Prices go up.\n",
      "\n",
      "LLM Answer: When corporations don't have to compete, their profits go up, and as a result, prices go up as well. This lack of competition allows corporations to have more control over the market, leading to higher prices for consumers. Additionally, small businesses and family farmers and ranchers may struggle or go under because they cannot compete with these dominant corporations.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "QA number 5 \n",
      "\n",
      "Question: What did foreign-owned ocean carriers do during the pandemic?\n",
      "\n",
      "Answer: They raised prices by as much as 1,000% and made record profits.\n",
      "\n",
      "LLM Answer: During the pandemic, foreign-owned ocean carriers raised prices by as much as 1,000% and made record profits.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions_and_answers_llm = []\n",
    "for i, qa in enumerate(qna_GT):\n",
    "    question, answer = qa[\"question\"], qa[\"answer\"]\n",
    "    llm_answer = qa_rag_chain({\"query\": question})[\"result\"]\n",
    "    questions_and_answers_llm.append({\"question\": question, \"result\": llm_answer})\n",
    "    print(f\"QA number {i + 1} \\n\")\n",
    "    print(f\"Question: {question}\\n\")\n",
    "    print(f\"Answer: {answer}\\n\")\n",
    "    print(f\"LLM Answer: {llm_answer}\\n\")\n",
    "    print(\"--------------------------------------------------\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from langchain.evaluation import QAEvalChain\n",
    "\n",
    "eval_prompt = GRADE_ANSWER_PROMPT\n",
    "\n",
    "eval_chain = QAEvalChain.from_llm(\n",
    "    llm=gpt35_azure_llm,\n",
    "    prompt=eval_prompt\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'results': \"GRADE: Correct\\n\\nJUSTIFICATION: The student answer accurately states that the purpose of the chief prosecutor for pandemic fraud is to go after the criminals who stole relief money meant for small businesses and Americans. The student's answer also includes additional information about investigating and prosecuting cases of fraud related to the misuse of funds intended for pandemic relief, which does not conflict with the true answer.\"},\n {'results': 'GRADE: Incorrect\\n\\nJUSTIFICATION: The student answer states that there is no specific information provided in the context about the projected reduction of the deficit by the end of this year. However, the true answer does provide specific information, stating that the deficit will be reduced to less than half of what it was before the current president took office.'},\n {'results': 'GRADE: Correct\\n\\nJUSTIFICATION: The student answer accurately explains that the speaker believes capitalism without competition leads to exploitation and higher prices for consumers, which aligns with the true answer.'},\n {'results': \"GRADE: Correct\\n\\nJUSTIFICATION: The student answer accurately states that when corporations don't have to compete, prices go up. Additionally, the student provides additional information about the effects of lack of competition on small businesses and family farmers and ranchers, which does not conflict with the true answer.\"},\n {'results': 'GRADE: Correct\\n\\nJUSTIFICATION: The student answer accurately states that foreign-owned ocean carriers raised prices by as much as 1,000% and made record profits during the pandemic, which matches the true answer.'}]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graded_outputs = eval_chain.evaluate(\n",
    "    examples=qna_GT,\n",
    "    predictions=questions_and_answers_llm,\n",
    "    question_key=\"question\",\n",
    "    prediction_key=\"result\"\n",
    ")\n",
    "graded_outputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRADE: Correct\n",
      "\n",
      "JUSTIFICATION: The student answer accurately states that the purpose of the chief prosecutor for pandemic fraud is to go after the criminals who stole relief money meant for small businesses and Americans. The student's answer also includes additional information about investigating and prosecuting cases of fraud related to the misuse of funds intended for pandemic relief, which does not conflict with the true answer.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "GRADE: Incorrect\n",
      "\n",
      "JUSTIFICATION: The student answer states that there is no specific information provided in the context about the projected reduction of the deficit by the end of this year. However, the true answer does provide specific information, stating that the deficit will be reduced to less than half of what it was before the current president took office.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "GRADE: Correct\n",
      "\n",
      "JUSTIFICATION: The student answer accurately explains that the speaker believes capitalism without competition leads to exploitation and higher prices for consumers, which aligns with the true answer.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "GRADE: Correct\n",
      "\n",
      "JUSTIFICATION: The student answer accurately states that when corporations don't have to compete, prices go up. Additionally, the student provides additional information about the effects of lack of competition on small businesses and family farmers and ranchers, which does not conflict with the true answer.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "GRADE: Correct\n",
      "\n",
      "JUSTIFICATION: The student answer accurately states that foreign-owned ocean carriers raised prices by as much as 1,000% and made record profits during the pandemic, which matches the true answer.\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for qa_grade in graded_outputs:\n",
    "    print(f\"{qa_grade['results']}\")\n",
    "    print(\"--------------------------------------------------\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "openai_azure_embeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=\"02e3dbabaf334ccb959cbeadbd3f99c3\",\n",
    "    openai_api_base=\"https://llm-x-gpt.openai.azure.com/\",\n",
    "    deployment_name='LLM-X-Embedding'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "Resource not found",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidRequestError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[69], line 9\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mevaluation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m EmbeddingDistance\n\u001B[1;32m      4\u001B[0m evaluator \u001B[38;5;241m=\u001B[39m load_evaluator(evaluator\u001B[38;5;241m=\u001B[39mEvaluatorType\u001B[38;5;241m.\u001B[39mPAIRWISE_EMBEDDING_DISTANCE,\n\u001B[1;32m      5\u001B[0m                            distance_metric\u001B[38;5;241m=\u001B[39mEmbeddingDistance\u001B[38;5;241m.\u001B[39mCOSINE,\n\u001B[1;32m      6\u001B[0m                            embeddings\u001B[38;5;241m=\u001B[39mopenai_azure_embeddings,\n\u001B[1;32m      7\u001B[0m                            llm\u001B[38;5;241m=\u001B[39mgpt35_azure_llm)\n\u001B[0;32m----> 9\u001B[0m \u001B[43mevaluator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate_string_pairs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprediction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSeattle is very hot in June\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction_b\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSeattle is cool in June.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[1;32m     11\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/evaluation/schema.py:294\u001B[0m, in \u001B[0;36mPairwiseStringEvaluator.evaluate_string_pairs\u001B[0;34m(self, prediction, prediction_b, reference, input, **kwargs)\u001B[0m\n\u001B[1;32m    282\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Evaluate the output string pairs.\u001B[39;00m\n\u001B[1;32m    283\u001B[0m \n\u001B[1;32m    284\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    291\u001B[0m \u001B[38;5;124;03m    dict: A dictionary containing the preference, scores, and/or other information.\u001B[39;00m\n\u001B[1;32m    292\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m  \u001B[38;5;66;03m# noqa: E501\u001B[39;00m\n\u001B[1;32m    293\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_evaluation_args(reference\u001B[38;5;241m=\u001B[39mreference, \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m--> 294\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_evaluate_string_pairs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    295\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprediction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprediction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    296\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprediction_b\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprediction_b\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    297\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreference\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreference\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    298\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    299\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    300\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/evaluation/embedding_distance/base.py:435\u001B[0m, in \u001B[0;36mPairwiseEmbeddingDistanceEvalChain._evaluate_string_pairs\u001B[0;34m(self, prediction, prediction_b, callbacks, tags, metadata, include_run_info, **kwargs)\u001B[0m\n\u001B[1;32m    409\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_evaluate_string_pairs\u001B[39m(\n\u001B[1;32m    410\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    411\u001B[0m     \u001B[38;5;241m*\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    418\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[1;32m    419\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mdict\u001B[39m:\n\u001B[1;32m    420\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Evaluate the embedding distance between two predictions.\u001B[39;00m\n\u001B[1;32m    421\u001B[0m \n\u001B[1;32m    422\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    433\u001B[0m \u001B[38;5;124;03m                predictions.\u001B[39;00m\n\u001B[1;32m    434\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 435\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    436\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprediction\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprediction_b\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprediction_b\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    437\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    438\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtags\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    439\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    440\u001B[0m \u001B[43m        \u001B[49m\u001B[43minclude_run_info\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude_run_info\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    441\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    442\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_output(result)\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/chains/base.py:258\u001B[0m, in \u001B[0;36mChain.__call__\u001B[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001B[0m\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    257\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n\u001B[0;32m--> 258\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    259\u001B[0m run_manager\u001B[38;5;241m.\u001B[39mon_chain_end(outputs)\n\u001B[1;32m    260\u001B[0m final_outputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(\n\u001B[1;32m    261\u001B[0m     inputs, outputs, return_only_outputs\n\u001B[1;32m    262\u001B[0m )\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/chains/base.py:252\u001B[0m, in \u001B[0;36mChain.__call__\u001B[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001B[0m\n\u001B[1;32m    246\u001B[0m run_manager \u001B[38;5;241m=\u001B[39m callback_manager\u001B[38;5;241m.\u001B[39mon_chain_start(\n\u001B[1;32m    247\u001B[0m     dumpd(\u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    248\u001B[0m     inputs,\n\u001B[1;32m    249\u001B[0m )\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 252\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    253\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[1;32m    254\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(inputs)\n\u001B[1;32m    255\u001B[0m     )\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    257\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/evaluation/embedding_distance/base.py:380\u001B[0m, in \u001B[0;36mPairwiseEmbeddingDistanceEvalChain._call\u001B[0;34m(self, inputs, run_manager)\u001B[0m\n\u001B[1;32m    364\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call\u001B[39m(\n\u001B[1;32m    365\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    366\u001B[0m     inputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any],\n\u001B[1;32m    367\u001B[0m     run_manager: Optional[CallbackManagerForChainRun] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    368\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, Any]:\n\u001B[1;32m    369\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute the score for two predictions.\u001B[39;00m\n\u001B[1;32m    370\u001B[0m \n\u001B[1;32m    371\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    377\u001B[0m \u001B[38;5;124;03m        Dict[str, Any]: The computed score.\u001B[39;00m\n\u001B[1;32m    378\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m    379\u001B[0m     vectors \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\n\u001B[0;32m--> 380\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membeddings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_documents\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    381\u001B[0m \u001B[43m            \u001B[49m\u001B[43m[\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprediction\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprediction_b\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    382\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    383\u001B[0m     )\n\u001B[1;32m    384\u001B[0m     score \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compute_score(vectors)\n\u001B[1;32m    385\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m\"\u001B[39m: score}\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/embeddings/openai.py:478\u001B[0m, in \u001B[0;36mOpenAIEmbeddings.embed_documents\u001B[0;34m(self, texts, chunk_size)\u001B[0m\n\u001B[1;32m    466\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Call out to OpenAI's embedding endpoint for embedding search docs.\u001B[39;00m\n\u001B[1;32m    467\u001B[0m \n\u001B[1;32m    468\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    474\u001B[0m \u001B[38;5;124;03m    List of embeddings, one for each text.\u001B[39;00m\n\u001B[1;32m    475\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    476\u001B[0m \u001B[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001B[39;00m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001B[39;00m\n\u001B[0;32m--> 478\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_len_safe_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdeployment\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/embeddings/openai.py:364\u001B[0m, in \u001B[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001B[0;34m(self, texts, engine, chunk_size)\u001B[0m\n\u001B[1;32m    361\u001B[0m     _iter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(tokens), _chunk_size)\n\u001B[1;32m    363\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m _iter:\n\u001B[0;32m--> 364\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43membed_with_retry\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    365\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    366\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokens\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m_chunk_size\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    367\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_invocation_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    368\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    369\u001B[0m     batched_embeddings\u001B[38;5;241m.\u001B[39mextend(r[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124membedding\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m r \u001B[38;5;129;01min\u001B[39;00m response[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m    371\u001B[0m results: List[List[List[\u001B[38;5;28mfloat\u001B[39m]]] \u001B[38;5;241m=\u001B[39m [[] \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(texts))]\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/embeddings/openai.py:107\u001B[0m, in \u001B[0;36membed_with_retry\u001B[0;34m(embeddings, **kwargs)\u001B[0m\n\u001B[1;32m    104\u001B[0m     response \u001B[38;5;241m=\u001B[39m embeddings\u001B[38;5;241m.\u001B[39mclient\u001B[38;5;241m.\u001B[39mcreate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    105\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _check_response(response)\n\u001B[0;32m--> 107\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_embed_with_retry\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/tenacity/__init__.py:289\u001B[0m, in \u001B[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001B[0;34m(*args, **kw)\u001B[0m\n\u001B[1;32m    287\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(f)\n\u001B[1;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_f\u001B[39m(\u001B[38;5;241m*\u001B[39margs: t\u001B[38;5;241m.\u001B[39mAny, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: t\u001B[38;5;241m.\u001B[39mAny) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m t\u001B[38;5;241m.\u001B[39mAny:\n\u001B[0;32m--> 289\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/tenacity/__init__.py:379\u001B[0m, in \u001B[0;36mRetrying.__call__\u001B[0;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m    377\u001B[0m retry_state \u001B[38;5;241m=\u001B[39m RetryCallState(retry_object\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m, fn\u001B[38;5;241m=\u001B[39mfn, args\u001B[38;5;241m=\u001B[39margs, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[1;32m    378\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 379\u001B[0m     do \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    380\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoAttempt):\n\u001B[1;32m    381\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/tenacity/__init__.py:314\u001B[0m, in \u001B[0;36mBaseRetrying.iter\u001B[0;34m(self, retry_state)\u001B[0m\n\u001B[1;32m    312\u001B[0m is_explicit_retry \u001B[38;5;241m=\u001B[39m fut\u001B[38;5;241m.\u001B[39mfailed \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(fut\u001B[38;5;241m.\u001B[39mexception(), TryAgain)\n\u001B[1;32m    313\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (is_explicit_retry \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mretry(retry_state)):\n\u001B[0;32m--> 314\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfut\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mafter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    317\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mafter(retry_state)\n",
      "File \u001B[0;32m/opt/miniconda/lib/python3.9/concurrent/futures/_base.py:439\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    437\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[1;32m    438\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m--> 439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    441\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_condition\u001B[38;5;241m.\u001B[39mwait(timeout)\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001B[0;32m/opt/miniconda/lib/python3.9/concurrent/futures/_base.py:391\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    389\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[1;32m    390\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 391\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[1;32m    392\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    393\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[1;32m    394\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/tenacity/__init__.py:382\u001B[0m, in \u001B[0;36mRetrying.__call__\u001B[0;34m(self, fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m    380\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoAttempt):\n\u001B[1;32m    381\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 382\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    383\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m:  \u001B[38;5;66;03m# noqa: B902\u001B[39;00m\n\u001B[1;32m    384\u001B[0m         retry_state\u001B[38;5;241m.\u001B[39mset_exception(sys\u001B[38;5;241m.\u001B[39mexc_info())  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/langchain/embeddings/openai.py:104\u001B[0m, in \u001B[0;36membed_with_retry.<locals>._embed_with_retry\u001B[0;34m(**kwargs)\u001B[0m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;129m@retry_decorator\u001B[39m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_embed_with_retry\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[0;32m--> 104\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43membeddings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    105\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _check_response(response)\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/openai/api_resources/embedding.py:33\u001B[0m, in \u001B[0;36mEmbedding.create\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 33\u001B[0m         response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m         \u001B[38;5;66;03m# If a user specifies base64, we'll just return the encoded string.\u001B[39;00m\n\u001B[1;32m     36\u001B[0m         \u001B[38;5;66;03m# This is only for the default case.\u001B[39;00m\n\u001B[1;32m     37\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m user_provided_encoding_format:\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001B[0m, in \u001B[0;36mEngineAPIResource.create\u001B[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m    129\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[1;32m    137\u001B[0m ):\n\u001B[1;32m    138\u001B[0m     (\n\u001B[1;32m    139\u001B[0m         deployment_id,\n\u001B[1;32m    140\u001B[0m         engine,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    150\u001B[0m         api_key, api_base, api_type, api_version, organization, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\n\u001B[1;32m    151\u001B[0m     )\n\u001B[0;32m--> 153\u001B[0m     response, _, api_key \u001B[38;5;241m=\u001B[39m \u001B[43mrequestor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpost\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stream:\n\u001B[1;32m    164\u001B[0m         \u001B[38;5;66;03m# must be an iterator\u001B[39;00m\n\u001B[1;32m    165\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, OpenAIResponse)\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/openai/api_requestor.py:298\u001B[0m, in \u001B[0;36mAPIRequestor.request\u001B[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[1;32m    278\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    279\u001B[0m     method,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    286\u001B[0m     request_timeout: Optional[Union[\u001B[38;5;28mfloat\u001B[39m, Tuple[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mfloat\u001B[39m]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    287\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[1;32m    288\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest_raw(\n\u001B[1;32m    289\u001B[0m         method\u001B[38;5;241m.\u001B[39mlower(),\n\u001B[1;32m    290\u001B[0m         url,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    296\u001B[0m         request_timeout\u001B[38;5;241m=\u001B[39mrequest_timeout,\n\u001B[1;32m    297\u001B[0m     )\n\u001B[0;32m--> 298\u001B[0m     resp, got_stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpret_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    299\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m resp, got_stream, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/openai/api_requestor.py:700\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response\u001B[0;34m(self, result, stream)\u001B[0m\n\u001B[1;32m    692\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[1;32m    693\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_interpret_response_line(\n\u001B[1;32m    694\u001B[0m             line, result\u001B[38;5;241m.\u001B[39mstatus_code, result\u001B[38;5;241m.\u001B[39mheaders, stream\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    695\u001B[0m         )\n\u001B[1;32m    696\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m parse_stream(result\u001B[38;5;241m.\u001B[39miter_lines())\n\u001B[1;32m    697\u001B[0m     ), \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    698\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    699\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m--> 700\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpret_response_line\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    701\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    702\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstatus_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    703\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    704\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    705\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m    706\u001B[0m         \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    707\u001B[0m     )\n",
      "File \u001B[0;32m~/.virtualenvs/QnAEvaluation/lib/python3.9/site-packages/openai/api_requestor.py:763\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response_line\u001B[0;34m(self, rbody, rcode, rheaders, stream)\u001B[0m\n\u001B[1;32m    761\u001B[0m stream_error \u001B[38;5;241m=\u001B[39m stream \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124merror\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m resp\u001B[38;5;241m.\u001B[39mdata\n\u001B[1;32m    762\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m stream_error \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;241m200\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m rcode \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m300\u001B[39m:\n\u001B[0;32m--> 763\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_error_response(\n\u001B[1;32m    764\u001B[0m         rbody, rcode, resp\u001B[38;5;241m.\u001B[39mdata, rheaders, stream_error\u001B[38;5;241m=\u001B[39mstream_error\n\u001B[1;32m    765\u001B[0m     )\n\u001B[1;32m    766\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "\u001B[0;31mInvalidRequestError\u001B[0m: Resource not found"
     ]
    }
   ],
   "source": [
    "from langchain.evaluation import load_evaluator, EvaluatorType\n",
    "from langchain.evaluation import EmbeddingDistance\n",
    "\n",
    "evaluator = load_evaluator(evaluator=EvaluatorType.PAIRWISE_EMBEDDING_DISTANCE,\n",
    "                           distance_metric=EmbeddingDistance.COSINE,\n",
    "                           embeddings=openai_azure_embeddings,\n",
    "                           llm=gpt35_azure_llm)\n",
    "\n",
    "evaluator.evaluate_string_pairs(\n",
    "    prediction=\"Seattle is very hot in June\", prediction_b=\"Seattle is cool in June.\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluator.l  QA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "PairwiseEmbeddingDistanceEvalChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, metadata=None, embeddings=OpenAIEmbeddings(client=<class 'openai.api_resources.embedding.Embedding'>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version='', openai_api_base='https://llm-x-gpt.openai.azure.com/', openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key='02e3dbabaf334ccb959cbeadbd3f99c3', openai_organization='', allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=6, request_timeout=None, headers=None, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={'deployment_name': 'LLM-X-Embedding'}), distance_metric=<EmbeddingDistance.COSINE: 'cosine'>)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.evaluation import PairwiseEmbeddingDistanceEvalChain\n",
    "\n",
    "PairwiseEmbeddingDistanceEvalChain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "def run_evaluation(qa_rag_chain, qna_GT):\n",
    "    predictions_list = []\n",
    "\n",
    "    for qna in qna_GT:\n",
    "        question, answer = qna[\"question\"], qna[\"answer\"]\n",
    "        qa_rag_chain_answer = qa_rag_chain({\"query\": question})[\"result\"]\n",
    "        predictions_list.append({\"question\": question, \"answer\": answer, \"result\": qa_rag_chain_answer})\n",
    "\n",
    "    answers_grade = grade_model_answer(qna_GT, predictions_list)\n",
    "\n",
    "    return answers_grade, predictions_list\n",
    "\n",
    "\n",
    "def grade_model_answer(qna_GT: List, predictions: List) -> List:\n",
    "    graded_outputs = []\n",
    "\n",
    "    evaluator = load_evaluator(evaluator=EvaluatorType.LABELED_CRITERIA,\n",
    "                           criteria=\"correctness\",\n",
    "                           llm=gpt35_azure_llm)\n",
    "\n",
    "    for i, qna in enumerate(qna_GT):\n",
    "        question, answer = qna[\"question\"], qna[\"answer\"]\n",
    "        grade = evaluator.evaluate_strings(input=question,\n",
    "                                         prediction=predictions[i],\n",
    "                                         reference=answer)\n",
    "        graded_outputs.append(grade['score'])\n",
    "\n",
    "    return graded_outputs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "answers_grade, predictions_list = run_evaluation(qa_rag_chain, qna_GT)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "([1, 1, None, 1, None],\n [],\n [],\n [{'question': 'What is the purpose of the chief prosecutor for pandemic fraud?',\n   'answer': 'To go after the criminals who stole relief money meant for small businesses and Americans.',\n   'result': 'The purpose of the chief prosecutor for pandemic fraud is to go after the criminals who stole billions in relief money meant for small businesses and millions of Americans. They will be responsible for investigating and prosecuting cases of fraud related to the misuse of funds intended for pandemic relief.'},\n  {'question': 'How much will the deficit be reduced to by the end of this year?',\n   'answer': 'Less than half of what it was before the current president took office.',\n   'result': \"The given context does not provide specific information about the projected reduction of the deficit by the end of this year. Therefore, I don't have the information to answer your question.\"},\n  {'question': \"What does the speaker mean by 'capitalism without competition isn't capitalism'?\",\n   'answer': 'The speaker believes that true capitalism requires competition, and without it, it becomes exploitation.',\n   'result': \"The speaker means that true capitalism requires competition. Without competition, capitalism becomes exploitative and leads to higher prices for consumers. The speaker believes that when corporations don't have to compete, they can drive up prices, harm small businesses, and exploit consumers.\"},\n  {'question': \"What happens to prices when corporations don't have to compete?\",\n   'answer': 'Prices go up.',\n   'result': \"When corporations don't have to compete, their profits go up, and as a result, prices go up as well. This lack of competition allows corporations to have more control over the market, leading to higher prices for consumers. Additionally, small businesses and family farmers and ranchers may struggle or go under because they cannot compete with these dominant corporations.\"},\n  {'question': 'What did foreign-owned ocean carriers do during the pandemic?',\n   'answer': 'They raised prices by as much as 1,000% and made record profits.',\n   'result': 'During the pandemic, foreign-owned ocean carriers raised prices by as much as 1,000% and made record profits.'}])"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_grade"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
